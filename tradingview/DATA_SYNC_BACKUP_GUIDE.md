# TradingViewæ•°æ®åŒæ­¥å’Œå¤‡ä»½ç³»ç»Ÿä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#-ç³»ç»Ÿæ¦‚è¿°)
2. [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
3. [æ•°æ®åŒæ­¥](#-æ•°æ®åŒæ­¥)
4. [æ•°æ®å¤‡ä»½](#-æ•°æ®å¤‡ä»½)
5. [é…ç½®ç®¡ç†](#-é…ç½®ç®¡ç†)
6. [CLIå·¥å…·ä½¿ç”¨](#-cliå·¥å…·ä½¿ç”¨)
7. [ç›‘æ§å’Œè¿ç»´](#-ç›‘æ§å’Œè¿ç»´)
8. [æœ€ä½³å®è·µ](#-æœ€ä½³å®è·µ)
9. [æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤)

---

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

TradingViewæ•°æ®åŒæ­¥å’Œå¤‡ä»½ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

### æ ¸å¿ƒåŠŸèƒ½

- **ğŸ“Š å¤šæºæ•°æ®åŒæ­¥**: æ”¯æŒä¸»æ•°æ®æºã€ç¼“å­˜ã€å¤‡ä»½ä¹‹é—´çš„çµæ´»åŒæ­¥
- **ğŸ’¾ å¤šç±»å‹å¤‡ä»½**: å…¨é‡å¤‡ä»½ã€å¢é‡å¤‡ä»½ã€å¿«ç…§å¤‡ä»½ã€å·®å¼‚å¤‡ä»½
- **â° å®šæ—¶ä»»åŠ¡è°ƒåº¦**: åŸºäºCronè¡¨è¾¾å¼çš„çµæ´»ä»»åŠ¡è°ƒåº¦
- **ğŸ” å®æ—¶ç›‘æ§**: å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡å’Œå¥åº·æ£€æŸ¥
- **ğŸ› ï¸ CLIç®¡ç†å·¥å…·**: å‘½ä»¤è¡Œç•Œé¢æ–¹ä¾¿è¿ç»´ç®¡ç†
- **âš¡ é«˜æ€§èƒ½è®¾è®¡**: å¼‚æ­¥å¤„ç†ã€å¹¶å‘æ§åˆ¶ã€æ™ºèƒ½ç¼“å­˜

### æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æ•°æ®åŒæ­¥å¤‡ä»½ç³»ç»Ÿæ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“Š æ•°æ®æºå±‚                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ TradingView â”‚  â”‚  ç¼“å­˜ç³»ç»Ÿ   â”‚  â”‚   å¤‡ä»½å­˜å‚¨   â”‚            â”‚
â”‚  â”‚  (Primary)  â”‚  â”‚  (Cache)    â”‚  â”‚  (Backup)    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                 â”‚                 â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                           â”‚                                    â”‚
â”‚  ğŸ”„ åŒæ­¥å¼•æ“å±‚             â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           DataSyncEngine (å¼‚æ­¥ä»»åŠ¡è°ƒåº¦)                     â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚ â€¢ ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†  â€¢ å¹¶å‘æ§åˆ¶  â€¢ é‡è¯•æœºåˆ¶  â€¢ æ€§èƒ½ç›‘æ§         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                    â”‚
â”‚  ğŸ’¾ å¤‡ä»½ç®¡ç†å±‚             â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚          DataBackupManager (å¤‡ä»½ç”Ÿå‘½å‘¨æœŸç®¡ç†)               â”‚ â”‚
â”‚  â”‚                                                             â”‚ â”‚
â”‚  â”‚ â€¢ å¤šç±»å‹å¤‡ä»½  â€¢ ç‰ˆæœ¬ç®¡ç†  â€¢ æ ¡éªŒæ¢å¤  â€¢ æ¸…ç†ç­–ç•¥           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…ä¾èµ–
pip install asyncio pyyaml schedule prometheus_client

# 2. åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p data/backups
mkdir -p logs

# 3. æ£€æŸ¥é…ç½®æ–‡ä»¶
ls tradingview/sync_backup_config.yaml
```

### 30ç§’å¿«é€Ÿä½“éªŒ

```bash
# 1. è¿è¡Œç³»ç»Ÿæµ‹è¯•
python tradingview/sync_backup_cli.py test

# 2. æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
python tradingview/sync_backup_cli.py status

# 3. åˆ›å»ºå¿«ç…§å¤‡ä»½
python tradingview/sync_backup_cli.py backup --type snapshot

# 4. åˆ—å‡ºæ‰€æœ‰å¤‡ä»½
python tradingview/sync_backup_cli.py list backups
```

### Python API å¿«é€Ÿä½¿ç”¨

```python
import asyncio
from tradingview.data_sync_backup import DataSyncBackupController, BackupType

async def quick_demo():
    # åˆå§‹åŒ–æ§åˆ¶å™¨
    controller = DataSyncBackupController()
    
    try:
        # å¯åŠ¨ç³»ç»Ÿ
        await controller.start()
        
        # åˆ›å»ºå¤‡ä»½
        backup_id = await controller.create_manual_backup(
            BackupType.FULL,
            symbols=['BINANCE:BTCUSDT'],
            timeframes=['15']
        )
        
        print(f"å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_id}")
        
        # æ‰§è¡ŒåŒæ­¥
        task_id = await controller.sync_data(
            source_type="primary",
            target_type="cache",
            symbols=['BINANCE:BTCUSDT'],
            timeframes=['15']
        )
        
        print(f"åŒæ­¥ä»»åŠ¡å¯åŠ¨: {task_id}")
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await asyncio.sleep(5)
        
        # æŸ¥çœ‹çŠ¶æ€
        status = controller.get_system_status()
        print(f"ç³»ç»ŸçŠ¶æ€: {status}")
        
    finally:
        await controller.stop()

# è¿è¡Œæ¼”ç¤º
asyncio.run(quick_demo())
```

---

## ğŸ”„ æ•°æ®åŒæ­¥

### åŒæ­¥ç±»å‹å’Œæ–¹å‘

| æºç±»å‹ | ç›®æ ‡ç±»å‹ | æè¿° | ä½¿ç”¨åœºæ™¯ |
|--------|----------|------|----------|
| primary | cache | ä¸»æ•°æ®æºåˆ°ç¼“å­˜ | å®æ—¶æ•°æ®æ›´æ–° |
| cache | backup | ç¼“å­˜åˆ°å¤‡ä»½ | å®šæœŸæ•°æ®å¤‡ä»½ |
| backup | cache | å¤‡ä»½åˆ°ç¼“å­˜ | ç¾éš¾æ¢å¤ |
| cache | remote | ç¼“å­˜åˆ°è¿œç¨‹ | æ•°æ®åˆ†å‘ |

### åŒæ­¥ç­–ç•¥é…ç½®

```yaml
# sync_backup_config.yaml
sync_config:
  sync_interval: 300                    # åŒæ­¥é—´éš”(ç§’)
  batch_size: 100                       # æ‰¹å¤„ç†å¤§å°
  max_concurrent_tasks: 5               # æœ€å¤§å¹¶å‘ä»»åŠ¡
  
  # ä¼˜å…ˆçº§å“ç§å’Œæ—¶é—´æ¡†æ¶
  priority_symbols:
    - "BINANCE:BTCUSDT"
    - "BINANCE:ETHUSDT"
  
  priority_timeframes:
    - "1"      # 1åˆ†é’Ÿ
    - "15"     # 15åˆ†é’Ÿ
```

### ç¼–ç¨‹å¼åŒæ­¥

```python
from tradingview.data_sync_backup import DataSyncEngine, SyncTask

async def custom_sync_example():
    # åˆ›å»ºåŒæ­¥å¼•æ“
    sync_engine = DataSyncEngine({
        'sync_interval': 60,
        'max_concurrent_tasks': 10
    })
    
    await sync_engine.start_sync_engine()
    
    # åˆ›å»ºè‡ªå®šä¹‰åŒæ­¥ä»»åŠ¡
    task = SyncTask(
        task_id="",
        source_type="primary",
        target_type="cache",
        symbols=['BINANCE:BTCUSDT', 'BINANCE:ETHUSDT'],
        timeframes=['5', '15', '60'],
        priority=1
    )
    
    # æ·»åŠ ä»»åŠ¡
    task_id = await sync_engine.add_sync_task(task)
    print(f"åŒæ­¥ä»»åŠ¡å·²æ·»åŠ : {task_id}")
    
    # ç›‘æ§ä»»åŠ¡çŠ¶æ€
    while True:
        status = sync_engine.get_sync_status()
        print(f"æ´»è·ƒä»»åŠ¡: {status['active_tasks']}")
        
        if status['active_tasks'] == 0:
            break
            
        await asyncio.sleep(1)
    
    await sync_engine.stop_sync_engine()
```

### CLIåŒæ­¥æ“ä½œ

```bash
# åŸºç¡€åŒæ­¥
python tradingview/sync_backup_cli.py sync \
  --source primary \
  --target cache \
  --symbols BINANCE:BTCUSDT,BINANCE:ETHUSDT \
  --timeframes 15,60

# å¸¦ç­‰å¾…çš„åŒæ­¥
python tradingview/sync_backup_cli.py sync \
  --source cache \
  --target backup \
  --symbols BINANCE:BTCUSDT \
  --wait

# æŸ¥çœ‹åŒæ­¥ä»»åŠ¡çŠ¶æ€
python tradingview/sync_backup_cli.py list tasks
```

---

## ğŸ’¾ æ•°æ®å¤‡ä»½

### å¤‡ä»½ç±»å‹è¯¦è§£

#### 1. å…¨é‡å¤‡ä»½ (Full Backup)
```bash
# å®Œæ•´çš„æ•°æ®å¤‡ä»½ï¼ŒåŒ…å«æ‰€æœ‰å†å²æ•°æ®
python tradingview/sync_backup_cli.py backup --type full

# æŒ‡å®šå“ç§çš„å…¨é‡å¤‡ä»½
python tradingview/sync_backup_cli.py backup \
  --type full \
  --symbols BINANCE:BTCUSDT,BINANCE:ETHUSDT \
  --timeframes 15,60
```

**ç‰¹ç‚¹**:
- åŒ…å«å®Œæ•´çš„å†å²æ•°æ®
- å¤‡ä»½æ—¶é—´è¾ƒé•¿ï¼Œæ–‡ä»¶è¾ƒå¤§
- å¯ç‹¬ç«‹æ¢å¤ï¼Œä¸ä¾èµ–å…¶ä»–å¤‡ä»½
- å»ºè®®æ¯æ—¥æˆ–æ¯å‘¨æ‰§è¡Œ

#### 2. å¢é‡å¤‡ä»½ (Incremental Backup)
```bash
# åªå¤‡ä»½è‡ªä¸Šæ¬¡å¤‡ä»½ä»¥æ¥çš„æ–°æ•°æ®
python tradingview/sync_backup_cli.py backup --type incremental
```

**ç‰¹ç‚¹**:
- åªå¤‡ä»½å˜åŒ–çš„æ•°æ®
- å¤‡ä»½é€Ÿåº¦å¿«ï¼Œæ–‡ä»¶å°
- æ¢å¤æ—¶éœ€è¦å®Œæ•´å¤‡ä»½é“¾
- å»ºè®®æ¯å°æ—¶æˆ–æ›´é¢‘ç¹æ‰§è¡Œ

#### 3. å¿«ç…§å¤‡ä»½ (Snapshot Backup)
```bash
# å¤‡ä»½å½“å‰æ—¶åˆ»çš„æ•°æ®çŠ¶æ€
python tradingview/sync_backup_cli.py backup --type snapshot
```

**ç‰¹ç‚¹**:
- æ•è·ç‰¹å®šæ—¶é—´ç‚¹çš„æ•°æ®çŠ¶æ€
- å¤‡ä»½å¿«é€Ÿï¼Œé€‚åˆé¢‘ç¹æ‰§è¡Œ
- ä¸»è¦ç”¨äºæµ‹è¯•å’ŒéªŒè¯
- å»ºè®®åœ¨é‡è¦æ“ä½œå‰æ‰§è¡Œ

### å¤‡ä»½ç®¡ç†

```python
from tradingview.data_sync_backup import DataBackupManager, BackupType

async def backup_management_example():
    # åˆ›å»ºå¤‡ä»½ç®¡ç†å™¨
    backup_manager = DataBackupManager({
        'backup_dir': 'data/backups',
        'max_backup_files': 50,
        'compression_enabled': True
    })
    
    # åˆ›å»ºå…¨é‡å¤‡ä»½
    backup_id = await backup_manager.create_backup(
        BackupType.FULL,
        symbols=['BINANCE:BTCUSDT'],
        timeframes=['15', '60']
    )
    
    print(f"å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_id}")
    
    # è·å–å¤‡ä»½ä¿¡æ¯
    backup_info = backup_manager.get_backup_info(backup_id)
    print(f"å¤‡ä»½å¤§å°: {backup_info['size_bytes']/1024/1024:.2f} MB")
    
    # æ¢å¤å¤‡ä»½
    success = await backup_manager.restore_backup(backup_id)
    print(f"å¤‡ä»½æ¢å¤: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
    
    # åˆ—å‡ºæ‰€æœ‰å¤‡ä»½
    all_backups = backup_manager.get_backup_info()
    for record in all_backups['backup_records']:
        print(f"å¤‡ä»½: {record['backup_id']} - {record['backup_type']}")
```

### å¤‡ä»½ç­–ç•¥é…ç½®

```yaml
# å¤‡ä»½ä¿ç•™ç­–ç•¥
backup_config:
  retention_policy:
    daily_backups: 7                    # ä¿ç•™7å¤©æ—¥å¤‡ä»½
    weekly_backups: 4                   # ä¿ç•™4å‘¨å‘¨å¤‡ä»½
    monthly_backups: 12                 # ä¿ç•™12ä¸ªæœˆæœˆå¤‡ä»½
    yearly_backups: 3                   # ä¿ç•™3å¹´å¹´å¤‡ä»½
  
  # å¤‡ä»½éªŒè¯
  verification:
    enable_checksum: true               # å¯ç”¨æ ¡éªŒå’Œ
    verify_after_backup: true          # å¤‡ä»½åç«‹å³éªŒè¯
    
  # å­˜å‚¨åç«¯
  storage_backends:
    local:
      enabled: true
      path: "data/backups/local"
    
    remote:
      enabled: false
      type: "s3"
      bucket: "tradingview-backups"
```

---

## âš™ï¸ é…ç½®ç®¡ç†

### ä¸»é…ç½®æ–‡ä»¶ç»“æ„

```yaml
# sync_backup_config.yaml

# æ•°æ®åŒæ­¥é…ç½®
sync_config:
  sync_interval: 300
  batch_size: 100
  max_concurrent_tasks: 5

# æ•°æ®å¤‡ä»½é…ç½®  
backup_config:
  backup_dir: "data/backups"
  max_backup_files: 30
  compression_enabled: true

# å®šæ—¶ä»»åŠ¡é…ç½®
schedule_config:
  enabled: true
  backup_schedules:
    full_backup:
      cron: "0 2 * * *"                # æ¯å¤©å‡Œæ™¨2ç‚¹
    incremental_backup:
      cron: "*/30 * * * *"             # æ¯30åˆ†é’Ÿ

# ç›‘æ§é…ç½®
monitoring_config:
  enabled: true
  metrics_port: 9090
  alerts:
    enabled: true
```

### åŠ¨æ€é…ç½®æ›´æ–°

```python
import yaml
from tradingview.data_sync_backup import DataSyncBackupController

async def update_config_example():
    # åŠ è½½å½“å‰é…ç½®
    with open('tradingview/sync_backup_config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # ä¿®æ”¹é…ç½®
    config['sync_config']['sync_interval'] = 180  # æ”¹ä¸º3åˆ†é’Ÿ
    config['backup_config']['max_backup_files'] = 50  # å¢åŠ å¤‡ä»½æ–‡ä»¶æ•°
    
    # ä¿å­˜é…ç½®
    with open('tradingview/sync_backup_config.yaml', 'w') as f:
        yaml.dump(config, f, indent=2)
    
    # é‡æ–°åˆå§‹åŒ–æ§åˆ¶å™¨
    controller = DataSyncBackupController(config)
    await controller.start()
    
    print("é…ç½®å·²æ›´æ–°å¹¶åº”ç”¨")
```

### ç¯å¢ƒç‰¹å®šé…ç½®

```bash
# å¼€å‘ç¯å¢ƒ
export SYNC_BACKUP_ENV=development
export SYNC_BACKUP_CONFIG=config/dev_sync_backup.yaml

# ç”Ÿäº§ç¯å¢ƒ
export SYNC_BACKUP_ENV=production  
export SYNC_BACKUP_CONFIG=config/prod_sync_backup.yaml

# ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®
export SYNC_INTERVAL=120
export BACKUP_DIR=/data/backups
export MAX_CONCURRENT_TASKS=8
```

---

## ğŸ› ï¸ CLIå·¥å…·ä½¿ç”¨

### åŸºç¡€å‘½ä»¤

```bash
# æŸ¥çœ‹å¸®åŠ©
python tradingview/sync_backup_cli.py --help

# æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
python tradingview/sync_backup_cli.py status

# è¯¦ç»†çŠ¶æ€è¾“å‡º
python tradingview/sync_backup_cli.py status --verbose
```

### å¤‡ä»½ç®¡ç†å‘½ä»¤

```bash
# åˆ›å»ºå…¨é‡å¤‡ä»½
python tradingview/sync_backup_cli.py backup --type full

# åˆ›å»ºæŒ‡å®šå“ç§çš„å¢é‡å¤‡ä»½
python tradingview/sync_backup_cli.py backup \
  --type incremental \
  --symbols BINANCE:BTCUSDT,BINANCE:ETHUSDT \
  --timeframes 15,60

# åˆ—å‡ºæ‰€æœ‰å¤‡ä»½
python tradingview/sync_backup_cli.py list backups

# è¯¦ç»†å¤‡ä»½ä¿¡æ¯
python tradingview/sync_backup_cli.py list backups --verbose

# æ¢å¤å¤‡ä»½
python tradingview/sync_backup_cli.py restore backup_full_1699123456

# å¼ºåˆ¶æ¢å¤å¤‡ä»½(ä¸æç¤ºç¡®è®¤)
python tradingview/sync_backup_cli.py restore backup_full_1699123456 --force

# æ¢å¤åˆ°æŒ‡å®šæ•°æ®åº“æ–‡ä»¶
python tradingview/sync_backup_cli.py restore backup_full_1699123456 \
  --target-db /path/to/target.db
```

### åŒæ­¥ç®¡ç†å‘½ä»¤

```bash
# æ‰§è¡Œä¸»æ•°æ®æºåˆ°ç¼“å­˜åŒæ­¥
python tradingview/sync_backup_cli.py sync \
  --source primary \
  --target cache \
  --symbols BINANCE:BTCUSDT

# æ‰§è¡Œç¼“å­˜åˆ°å¤‡ä»½åŒæ­¥å¹¶ç­‰å¾…å®Œæˆ
python tradingview/sync_backup_cli.py sync \
  --source cache \
  --target backup \
  --wait

# æŸ¥çœ‹åŒæ­¥ä»»åŠ¡çŠ¶æ€
python tradingview/sync_backup_cli.py list tasks

# è¯¦ç»†ä»»åŠ¡ä¿¡æ¯
python tradingview/sync_backup_cli.py list tasks --verbose
```

### å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼

```bash
# å¯åŠ¨å®ˆæŠ¤è¿›ç¨‹
python tradingview/sync_backup_cli.py daemon

# è¯¦ç»†è¾“å‡ºçš„å®ˆæŠ¤è¿›ç¨‹
python tradingview/sync_backup_cli.py daemon --verbose

# åå°è¿è¡Œå®ˆæŠ¤è¿›ç¨‹
nohup python tradingview/sync_backup_cli.py daemon > sync_backup.log 2>&1 &

# ä½¿ç”¨systemdç®¡ç†å®ˆæŠ¤è¿›ç¨‹
sudo systemctl start tradingview-sync-backup
sudo systemctl enable tradingview-sync-backup
```

### æµ‹è¯•å’Œè°ƒè¯•

```bash
# è¿è¡Œç³»ç»ŸåŠŸèƒ½æµ‹è¯•
python tradingview/sync_backup_cli.py test

# ä½¿ç”¨æŒ‡å®šé…ç½®æ–‡ä»¶
python tradingview/sync_backup_cli.py --config /path/to/config.yaml status

# è¯¦ç»†è°ƒè¯•è¾“å‡º
python tradingview/sync_backup_cli.py --verbose status
```

---

## ğŸ“Š ç›‘æ§å’Œè¿ç»´

### PrometheusæŒ‡æ ‡é›†æˆ

```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨
start_http_server(9090)

# å…³é”®æŒ‡æ ‡
sync_requests_total = Counter('sync_requests_total', 'Total sync requests', ['source', 'target'])
sync_duration_seconds = Histogram('sync_duration_seconds', 'Sync duration')
backup_size_bytes = Gauge('backup_size_bytes', 'Backup file size', ['backup_id'])
system_health_score = Gauge('system_health_score', 'System health score')

# åœ¨åº”ç”¨ä¸­è®°å½•æŒ‡æ ‡
sync_requests_total.labels(source='primary', target='cache').inc()
sync_duration_seconds.observe(processing_time)
backup_size_bytes.labels(backup_id='backup_123').set(file_size)
```

### å¥åº·æ£€æŸ¥ç«¯ç‚¹

```python
from fastapi import FastAPI
from tradingview.data_sync_backup import DataSyncBackupController

app = FastAPI()
controller = DataSyncBackupController()

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    status = controller.get_system_status()
    
    # è®¡ç®—å¥åº·åˆ†æ•°
    health_score = 1.0
    sync_engine = status.get('sync_engine', {})
    
    # æ£€æŸ¥æ´»è·ƒä»»åŠ¡æ•°
    if sync_engine.get('active_tasks', 0) > 10:
        health_score -= 0.2
    
    # æ£€æŸ¥å¤±è´¥ä»»åŠ¡æ•°
    if sync_engine.get('failed_tasks', 0) > 5:
        health_score -= 0.3
    
    # æ£€æŸ¥æœ€è¿‘é”™è¯¯
    if sync_engine.get('statistics', {}).get('last_error'):
        health_score -= 0.1
    
    return {
        "status": "healthy" if health_score > 0.7 else "unhealthy",
        "health_score": health_score,
        "details": status,
        "timestamp": int(time.time())
    }

@app.get("/metrics")
async def get_metrics():
    """Prometheusæ ¼å¼æŒ‡æ ‡"""
    status = controller.get_system_status()
    
    metrics = []
    
    # åŒæ­¥å¼•æ“æŒ‡æ ‡
    sync_stats = status.get('sync_engine', {})
    metrics.append(f"sync_active_tasks {sync_stats.get('active_tasks', 0)}")
    metrics.append(f"sync_completed_tasks {sync_stats.get('completed_tasks', 0)}")
    metrics.append(f"sync_failed_tasks {sync_stats.get('failed_tasks', 0)}")
    
    # å¤‡ä»½ç®¡ç†å™¨æŒ‡æ ‡
    backup_stats = status.get('backup_manager', {})
    metrics.append(f"backup_total_count {backup_stats.get('total_backups', 0)}")
    metrics.append(f"backup_total_size_mb {backup_stats.get('total_size_mb', 0)}")
    
    return "\n".join(metrics)
```

### æ—¥å¿—åˆ†æ

```python
import logging
from datetime import datetime, timedelta

class SyncBackupLogger:
    """åŒæ­¥å¤‡ä»½ä¸“ç”¨æ—¥å¿—å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger('sync_backup')
        self.handler = logging.FileHandler('logs/sync_backup.log')
        self.formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        self.handler.setFormatter(self.formatter)
        self.logger.addHandler(self.handler)
        self.logger.setLevel(logging.INFO)
    
    def log_sync_start(self, task_id: str, source: str, target: str):
        """è®°å½•åŒæ­¥å¼€å§‹"""
        self.logger.info(f"SYNC_START - Task: {task_id}, {source} -> {target}")
    
    def log_sync_complete(self, task_id: str, duration: float, records: int):
        """è®°å½•åŒæ­¥å®Œæˆ"""
        self.logger.info(f"SYNC_COMPLETE - Task: {task_id}, Duration: {duration:.2f}s, Records: {records}")
    
    def log_backup_create(self, backup_id: str, backup_type: str, size_mb: float):
        """è®°å½•å¤‡ä»½åˆ›å»º"""
        self.logger.info(f"BACKUP_CREATE - ID: {backup_id}, Type: {backup_type}, Size: {size_mb:.2f}MB")
    
    def log_error(self, operation: str, error: str):
        """è®°å½•é”™è¯¯"""
        self.logger.error(f"ERROR - Operation: {operation}, Error: {error}")
    
    def analyze_logs(self, hours: int = 24) -> Dict[str, Any]:
        """åˆ†ææ—¥å¿—"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        stats = {
            'sync_count': 0,
            'backup_count': 0,
            'error_count': 0,
            'avg_sync_duration': 0.0
        }
        
        try:
            with open('logs/sync_backup.log', 'r') as f:
                for line in f:
                    if 'SYNC_COMPLETE' in line:
                        stats['sync_count'] += 1
                    elif 'BACKUP_CREATE' in line:
                        stats['backup_count'] += 1
                    elif 'ERROR' in line:
                        stats['error_count'] += 1
        
        except FileNotFoundError:
            pass
        
        return stats

# ä½¿ç”¨ç¤ºä¾‹
logger = SyncBackupLogger()
logger.log_sync_start("task_123", "primary", "cache")
logger.log_sync_complete("task_123", 5.2, 1000)

# åˆ†ææœ€è¿‘24å°æ—¶çš„æ—¥å¿—
stats = logger.analyze_logs(24)
print(f"åŒæ­¥æ¬¡æ•°: {stats['sync_count']}")
print(f"å¤‡ä»½æ¬¡æ•°: {stats['backup_count']}")
print(f"é”™è¯¯æ¬¡æ•°: {stats['error_count']}")
```

### å‘Šè­¦é…ç½®

```yaml
# å‘Šè­¦è§„åˆ™é…ç½®
monitoring_config:
  alerts:
    enabled: true
    
    # å‘Šè­¦æ¸ é“
    channels:
      email:
        enabled: true
        smtp_server: "smtp.example.com"
        recipients: ["admin@example.com"]
      
      webhook:
        enabled: true
        url: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
      
      log:
        enabled: true
        level: "ERROR"
    
    # å‘Šè­¦è§„åˆ™
    rules:
      sync_failure_rate:
        condition: "sync_failure_rate > 0.1"
        threshold: 0.1
        severity: "critical"
        message: "åŒæ­¥å¤±è´¥ç‡è¶…è¿‡10%"
      
      backup_failure:
        condition: "backup_failure_count > 0"
        threshold: 0
        severity: "error"
        message: "å¤‡ä»½ä»»åŠ¡å¤±è´¥"
      
      disk_usage:
        condition: "disk_usage > 0.85"
        threshold: 0.85
        severity: "warning"
        message: "ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡85%"
```

---

## âœ… æœ€ä½³å®è·µ

### 1. å¤‡ä»½ç­–ç•¥æœ€ä½³å®è·µ

```yaml
# æ¨èçš„å¤‡ä»½ç­–ç•¥
backup_schedule:
  # å…¨é‡å¤‡ä»½ - æ¯å‘¨æ—¥å‡Œæ™¨2ç‚¹
  full_backup:
    cron: "0 2 * * 0"
    retention_days: 30
  
  # å¢é‡å¤‡ä»½ - æ¯4å°æ—¶
  incremental_backup:
    cron: "0 */4 * * *"
    retention_days: 7
  
  # å¿«ç…§å¤‡ä»½ - æ¯å°æ—¶
  snapshot_backup:
    cron: "0 * * * *"
    retention_days: 1
```

**åŸå› **:
- å…¨é‡å¤‡ä»½é¢‘ç‡ä½ä½†å®Œæ•´æ€§å¥½
- å¢é‡å¤‡ä»½å¹³è¡¡äº†å­˜å‚¨ç©ºé—´å’Œæ¢å¤æ—¶é—´
- å¿«ç…§å¤‡ä»½ç”¨äºå¿«é€Ÿæ•…éšœæ¢å¤

### 2. åŒæ­¥ä¼˜å…ˆçº§ç®¡ç†

```python
# æŒ‰é‡è¦æ€§å’Œæ´»è·ƒåº¦è®¾ç½®åŒæ­¥ä¼˜å…ˆçº§
sync_priority_config = {
    # é«˜ä¼˜å…ˆçº§ - çƒ­é—¨å“ç§ï¼Œé¢‘ç¹äº¤æ˜“
    'high_priority': {
        'symbols': ['BINANCE:BTCUSDT', 'BINANCE:ETHUSDT'],
        'timeframes': ['1', '5', '15'],
        'sync_interval': 60  # 1åˆ†é’ŸåŒæ­¥
    },
    
    # ä¸­ä¼˜å…ˆçº§ - é‡è¦å“ç§ï¼Œä¸­ç­‰æ´»è·ƒåº¦
    'medium_priority': {
        'symbols': ['BINANCE:ADAUSDT', 'FX:EURUSD'],
        'timeframes': ['15', '60'],
        'sync_interval': 300  # 5åˆ†é’ŸåŒæ­¥
    },
    
    # ä½ä¼˜å…ˆçº§ - å…¶ä»–å“ç§ï¼Œä½æ´»è·ƒåº¦
    'low_priority': {
        'symbols': ['*'],  # å…¶ä»–æ‰€æœ‰å“ç§
        'timeframes': ['60', '240'],
        'sync_interval': 1800  # 30åˆ†é’ŸåŒæ­¥
    }
}
```

### 3. æ€§èƒ½ä¼˜åŒ–é…ç½®

```yaml
# æ€§èƒ½ä¼˜åŒ–é…ç½®
sync_config:
  # æ ¹æ®ç³»ç»Ÿèµ„æºè°ƒæ•´
  max_concurrent_tasks: 8              # CPUæ ¸å¿ƒæ•°
  batch_size: 200                      # æ ¹æ®å†…å­˜å¤§å°è°ƒæ•´
  connection_pool_size: 16             # 2å€å¹¶å‘ä»»åŠ¡æ•°
  
  # ç½‘ç»œä¼˜åŒ–
  enable_compression: true
  keep_alive_timeout: 60
  connection_timeout: 30
  
  # é‡è¯•ç­–ç•¥
  max_retries: 3
  retry_delay_base: 2                  # æŒ‡æ•°é€€é¿

backup_config:
  # å­˜å‚¨ä¼˜åŒ–
  compression_enabled: true
  compression_level: 6                 # å¹³è¡¡å‹ç¼©ç‡å’Œé€Ÿåº¦
  
  # å¹¶å‘ä¼˜åŒ–
  max_backup_workers: 2                # é¿å…I/Oç«äº‰
  enable_async_io: true
```

### 4. èµ„æºç®¡ç†

```python
import psutil
import asyncio
from typing import Dict, Any

class ResourceManager:
    """èµ„æºä½¿ç”¨ç›‘æ§å’Œç®¡ç†"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.max_memory_percent = self.config.get('max_memory_percent', 80)
        self.max_cpu_percent = self.config.get('max_cpu_percent', 70)
        self.max_disk_percent = self.config.get('max_disk_percent', 85)
    
    def check_resources(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        memory = psutil.virtual_memory()
        cpu = psutil.cpu_percent(interval=1)
        disk = psutil.disk_usage('/')
        
        return {
            'memory_percent': memory.percent,
            'cpu_percent': cpu,
            'disk_percent': disk.percent,
            'memory_available_gb': memory.available / (1024**3),
            'disk_free_gb': disk.free / (1024**3)
        }
    
    def is_resource_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿèµ„æºæ‰§è¡Œä»»åŠ¡"""
        resources = self.check_resources()
        
        return (
            resources['memory_percent'] < self.max_memory_percent and
            resources['cpu_percent'] < self.max_cpu_percent and
            resources['disk_percent'] < self.max_disk_percent
        )
    
    async def wait_for_resources(self, timeout: int = 300):
        """ç­‰å¾…èµ„æºå¯ç”¨"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if self.is_resource_available():
                return True
            
            await asyncio.sleep(10)
        
        return False

# åœ¨åŒæ­¥ä»»åŠ¡ä¸­ä½¿ç”¨èµ„æºç®¡ç†
async def resource_aware_sync(controller, task):
    resource_manager = ResourceManager()
    
    # ç­‰å¾…èµ„æºå¯ç”¨
    if await resource_manager.wait_for_resources():
        # æ‰§è¡ŒåŒæ­¥ä»»åŠ¡
        return await controller.sync_data(task)
    else:
        raise Exception("ç³»ç»Ÿèµ„æºä¸è¶³ï¼Œè·³è¿‡åŒæ­¥ä»»åŠ¡")
```

### 5. é”™è¯¯å¤„ç†å’Œæ¢å¤

```python
from enum import Enum
import logging

class ErrorRecoveryStrategy(Enum):
    RETRY = "retry"
    SKIP = "skip"
    FALLBACK = "fallback"
    ALERT = "alert"

class ErrorHandler:
    """é”™è¯¯å¤„ç†å’Œæ¢å¤ç­–ç•¥"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.error_strategies = {
            ConnectionError: ErrorRecoveryStrategy.RETRY,
            TimeoutError: ErrorRecoveryStrategy.RETRY,
            ValueError: ErrorRecoveryStrategy.SKIP,
            MemoryError: ErrorRecoveryStrategy.ALERT,
            OSError: ErrorRecoveryStrategy.FALLBACK
        }
    
    async def handle_error(self, error: Exception, context: Dict[str, Any]) -> ErrorRecoveryStrategy:
        """å¤„ç†é”™è¯¯å¹¶è¿”å›æ¢å¤ç­–ç•¥"""
        error_type = type(error)
        strategy = self.error_strategies.get(error_type, ErrorRecoveryStrategy.ALERT)
        
        self.logger.error(f"é”™è¯¯å¤„ç†: {error_type.__name__}: {error}, ç­–ç•¥: {strategy.value}")
        
        if strategy == ErrorRecoveryStrategy.RETRY:
            return await self._handle_retry(error, context)
        elif strategy == ErrorRecoveryStrategy.FALLBACK:
            return await self._handle_fallback(error, context)
        elif strategy == ErrorRecoveryStrategy.ALERT:
            return await self._handle_alert(error, context)
        
        return strategy
    
    async def _handle_retry(self, error: Exception, context: Dict[str, Any]) -> ErrorRecoveryStrategy:
        """å¤„ç†é‡è¯•ç­–ç•¥"""
        retry_count = context.get('retry_count', 0)
        max_retries = context.get('max_retries', 3)
        
        if retry_count < max_retries:
            delay = 2 ** retry_count  # æŒ‡æ•°é€€é¿
            await asyncio.sleep(delay)
            return ErrorRecoveryStrategy.RETRY
        else:
            return ErrorRecoveryStrategy.ALERT
    
    async def _handle_fallback(self, error: Exception, context: Dict[str, Any]) -> ErrorRecoveryStrategy:
        """å¤„ç†åå¤‡ç­–ç•¥"""
        # å®ç°åå¤‡æ•°æ®æºæˆ–é™çº§æœåŠ¡
        self.logger.info("å¯ç”¨åå¤‡ç­–ç•¥")
        return ErrorRecoveryStrategy.FALLBACK
    
    async def _handle_alert(self, error: Exception, context: Dict[str, Any]) -> ErrorRecoveryStrategy:
        """å¤„ç†å‘Šè­¦ç­–ç•¥"""
        # å‘é€å‘Šè­¦é€šçŸ¥
        self.logger.critical(f"ä¸¥é‡é”™è¯¯éœ€è¦äººå·¥å¹²é¢„: {error}")
        return ErrorRecoveryStrategy.ALERT

# åœ¨åŒæ­¥è¿‡ç¨‹ä¸­ä½¿ç”¨é”™è¯¯å¤„ç†
async def resilient_sync_task(task):
    error_handler = ErrorHandler()
    
    for attempt in range(3):
        try:
            return await execute_sync_task(task)
        
        except Exception as e:
            strategy = await error_handler.handle_error(e, {
                'retry_count': attempt,
                'max_retries': 3,
                'task_id': task.task_id
            })
            
            if strategy != ErrorRecoveryStrategy.RETRY:
                break
    
    raise Exception(f"åŒæ­¥ä»»åŠ¡æœ€ç»ˆå¤±è´¥: {task.task_id}")
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. åŒæ­¥ä»»åŠ¡å †ç§¯

**ç—‡çŠ¶**: åŒæ­¥é˜Ÿåˆ—å¤§å°æŒç»­å¢é•¿ï¼Œæ´»è·ƒä»»åŠ¡æ•°å§‹ç»ˆä¸ºæœ€å¤§å€¼

```bash
# æ£€æŸ¥ç—‡çŠ¶
python tradingview/sync_backup_cli.py status
# è¾“å‡º: queue_size: 50, active_tasks: 5 (æŒç»­ä¸ä¸‹é™)
```

**åŸå› åˆ†æ**:
- å•ä¸ªä»»åŠ¡æ‰§è¡Œæ—¶é—´è¿‡é•¿
- æ•°æ®æºå“åº”æ…¢æˆ–ä¸ç¨³å®š
- ç³»ç»Ÿèµ„æºä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# 1. å¢åŠ å¹¶å‘ä»»åŠ¡æ•°
sync_config:
  max_concurrent_tasks: 10            # ä»5å¢åŠ åˆ°10

# 2. å‡å°‘æ‰¹å¤„ç†å¤§å°
sync_config:
  batch_size: 50                      # ä»100å‡å°‘åˆ°50

# 3. å¢åŠ è¶…æ—¶æ—¶é—´
sync_config:
  timeout_seconds: 60                 # ä»30å¢åŠ åˆ°60
```

```python
# 4. æ¸…ç†é˜Ÿåˆ—çš„ç´§æ€¥å¤„ç†
async def clear_sync_queue():
    controller = DataSyncBackupController()
    await controller.start()
    
    # è·å–åŒæ­¥å¼•æ“
    sync_engine = controller.sync_engine
    
    # æ¸…ç©ºé˜Ÿåˆ— (ç´§æ€¥æƒ…å†µä¸‹ä½¿ç”¨)
    while not sync_engine.task_queue.empty():
        try:
            task = sync_engine.task_queue.get_nowait()
            print(f"æ¸…ç†ä»»åŠ¡: {task.task_id}")
        except:
            break
    
    await controller.stop()
```

#### 2. å¤‡ä»½æ–‡ä»¶æŸå

**ç—‡çŠ¶**: å¤‡ä»½æ¢å¤æ—¶æç¤ºæ ¡éªŒå’Œä¸åŒ¹é…

```bash
# ç—‡çŠ¶
python tradingview/sync_backup_cli.py restore backup_full_1699123456
# è¾“å‡º: é”™è¯¯: å¤‡ä»½æ–‡ä»¶æ ¡éªŒå¤±è´¥
```

**è¯Šæ–­æ­¥éª¤**:
```python
import hashlib
from pathlib import Path

async def diagnose_backup_corruption(backup_id: str):
    """è¯Šæ–­å¤‡ä»½æ–‡ä»¶æŸå"""
    backup_manager = DataBackupManager()
    
    # è·å–å¤‡ä»½è®°å½•
    record = backup_manager.backup_records.get(backup_id)
    if not record:
        print(f"å¤‡ä»½è®°å½•ä¸å­˜åœ¨: {backup_id}")
        return
    
    backup_file = Path(record.file_path)
    if not backup_file.exists():
        print(f"å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
        return
    
    # é‡æ–°è®¡ç®—æ ¡éªŒå’Œ
    current_checksum = await backup_manager._calculate_checksum(backup_file)
    original_checksum = record.checksum
    
    print(f"åŸå§‹æ ¡éªŒå’Œ: {original_checksum}")
    print(f"å½“å‰æ ¡éªŒå’Œ: {current_checksum}")
    print(f"æ–‡ä»¶å®Œæ•´æ€§: {'âœ… å®Œå¥½' if current_checksum == original_checksum else 'âŒ æŸå'}")
    
    # æ£€æŸ¥æ–‡ä»¶æƒé™
    print(f"æ–‡ä»¶æƒé™: {oct(backup_file.stat().st_mode)}")
    print(f"æ–‡ä»¶å¤§å°: {backup_file.stat().st_size} bytes")
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. ä½¿ç”¨æœ€è¿‘çš„å¤‡ä»½æ¢å¤
python tradingview/sync_backup_cli.py list backups
python tradingview/sync_backup_cli.py restore <previous_backup_id>

# 2. åˆ›å»ºæ–°çš„å¤‡ä»½
python tradingview/sync_backup_cli.py backup --type full
```

#### 3. ç£ç›˜ç©ºé—´ä¸è¶³

**ç—‡çŠ¶**: å¤‡ä»½ä»»åŠ¡å¤±è´¥ï¼Œæç¤ºç£ç›˜ç©ºé—´ä¸è¶³

```bash
# æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µ
df -h
du -sh data/backups/*
```

**è§£å†³æ–¹æ¡ˆ**:
```python
import shutil
from pathlib import Path

async def cleanup_old_backups():
    """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶"""
    backup_manager = DataBackupManager()
    
    # è·å–æ‰€æœ‰å¤‡ä»½è®°å½•ï¼ŒæŒ‰æ—¶é—´æ’åº
    records = sorted(
        backup_manager.backup_records.values(),
        key=lambda x: x.created_at
    )
    
    # è®¡ç®—æ€»å¤§å°
    total_size = sum(record.size_bytes for record in records)
    print(f"å½“å‰å¤‡ä»½æ€»å¤§å°: {total_size / 1024 / 1024 / 1024:.2f} GB")
    
    # åˆ é™¤æœ€æ—§çš„å¤‡ä»½ç›´åˆ°ç©ºé—´å……è¶³
    target_size = total_size * 0.7  # ä¿ç•™70%
    current_size = total_size
    
    for record in records:
        if current_size <= target_size:
            break
        
        backup_file = Path(record.file_path)
        if backup_file.exists():
            backup_file.unlink()
            current_size -= record.size_bytes
            print(f"åˆ é™¤å¤‡ä»½: {record.backup_id}")
    
    print(f"æ¸…ç†åå¤§å°: {current_size / 1024 / 1024 / 1024:.2f} GB")
```

```yaml
# é…ç½®è‡ªåŠ¨æ¸…ç†ç­–ç•¥
backup_config:
  max_backup_files: 20                # å‡å°‘æœ€å¤§å¤‡ä»½æ–‡ä»¶æ•°
  max_total_size_gb: 50               # è®¾ç½®æ€»å¤§å°é™åˆ¶
  
  auto_cleanup:
    enabled: true
    size_threshold_gb: 40             # è¶…è¿‡40GBæ—¶è‡ªåŠ¨æ¸…ç†
    retention_policy:
      keep_latest: 5                  # å§‹ç»ˆä¿ç•™æœ€æ–°5ä¸ªå¤‡ä»½
      keep_daily: 7                   # ä¿ç•™7å¤©å†…çš„æ¯æ—¥å¤‡ä»½
```

#### 4. å†…å­˜ä½¿ç”¨è¿‡é«˜

**ç—‡çŠ¶**: ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡æŒç»­å‡é«˜ï¼Œå¯èƒ½å¯¼è‡´OOM

```python
import psutil
import gc

async def diagnose_memory_usage():
    """è¯Šæ–­å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process()
    memory_info = process.memory_info()
    
    print(f"è¿›ç¨‹å†…å­˜ä½¿ç”¨:")
    print(f"  RSS: {memory_info.rss / 1024 / 1024:.2f} MB")
    print(f"  VMS: {memory_info.vms / 1024 / 1024:.2f} MB")
    
    # ç³»ç»Ÿå†…å­˜
    system_memory = psutil.virtual_memory()
    print(f"ç³»ç»Ÿå†…å­˜:")
    print(f"  æ€»å†…å­˜: {system_memory.total / 1024 / 1024 / 1024:.2f} GB")
    print(f"  å·²ä½¿ç”¨: {system_memory.used / 1024 / 1024 / 1024:.2f} GB")
    print(f"  ä½¿ç”¨ç‡: {system_memory.percent:.1f}%")
    
    # åƒåœ¾å›æ”¶ç»Ÿè®¡
    gc_stats = gc.get_stats()
    print(f"åƒåœ¾å›æ”¶ç»Ÿè®¡: {gc_stats}")
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    collected = gc.collect()
    print(f"åƒåœ¾å›æ”¶é‡Šæ”¾å¯¹è±¡æ•°: {collected}")
```

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# 1. å‡å°‘ç¼“å­˜å¤§å°
sync_config:
  batch_size: 50                      # å‡å°‘æ‰¹å¤„ç†å¤§å°
  max_concurrent_tasks: 3             # å‡å°‘å¹¶å‘ä»»åŠ¡

# 2. å¯ç”¨å†…å­˜ç›‘æ§
monitoring_config:
  memory_monitoring:
    enabled: true
    max_memory_percent: 70            # è¶…è¿‡70%æ—¶å‘Šè­¦
    force_gc_threshold: 80            # è¶…è¿‡80%æ—¶å¼ºåˆ¶åƒåœ¾å›æ”¶
```

```python
# 3. å®ç°å†…å­˜ç›‘æ§å’Œè‡ªåŠ¨æ¸…ç†
class MemoryMonitor:
    def __init__(self, max_memory_percent: float = 80):
        self.max_memory_percent = max_memory_percent
    
    def check_memory_usage(self) -> float:
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡"""
        memory = psutil.virtual_memory()
        return memory.percent
    
    async def memory_cleanup_if_needed(self):
        """å¦‚æœéœ€è¦åˆ™è¿›è¡Œå†…å­˜æ¸…ç†"""
        usage = self.check_memory_usage()
        
        if usage > self.max_memory_percent:
            print(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {usage:.1f}%ï¼Œå¼€å§‹æ¸…ç†...")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            collected = gc.collect()
            print(f"åƒåœ¾å›æ”¶é‡Šæ”¾å¯¹è±¡: {collected}")
            
            # å†æ¬¡æ£€æŸ¥
            new_usage = self.check_memory_usage()
            print(f"æ¸…ç†åå†…å­˜ä½¿ç”¨ç‡: {new_usage:.1f}%")
            
            return new_usage < self.max_memory_percent
        
        return True

# åœ¨åŒæ­¥ä»»åŠ¡ä¸­ä½¿ç”¨å†…å­˜ç›‘æ§
async def memory_aware_sync_task(task):
    memory_monitor = MemoryMonitor(max_memory_percent=75)
    
    # ä»»åŠ¡æ‰§è¡Œå‰æ£€æŸ¥å†…å­˜
    if not await memory_monitor.memory_cleanup_if_needed():
        raise Exception("å†…å­˜ä¸è¶³ï¼Œè·³è¿‡åŒæ­¥ä»»åŠ¡")
    
    # æ‰§è¡Œä»»åŠ¡
    result = await execute_sync_task(task)
    
    # ä»»åŠ¡å®Œæˆåæ¸…ç†å†…å­˜
    await memory_monitor.memory_cleanup_if_needed()
    
    return result
```

### è°ƒè¯•å·¥å…·å’ŒæŠ€å·§

#### 1. è°ƒè¯•æ¨¡å¼å¯ç”¨

```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨è°ƒè¯•æ¨¡å¼
debug_config:
  debug_mode: true
  verbose_logging: true
  profile_performance: true
  dry_run: false                      # è®¾ä¸ºtrueåªæ¨¡æ‹Ÿä¸å®é™…æ‰§è¡Œ
```

#### 2. æ—¥å¿—åˆ†æè„šæœ¬

```python
import re
from datetime import datetime, timedelta
from collections import defaultdict

def analyze_sync_logs(log_file: str = "logs/sync_backup.log", hours: int = 24):
    """åˆ†æåŒæ­¥æ—¥å¿—"""
    cutoff_time = datetime.now() - timedelta(hours=hours)
    
    stats = {
        'sync_started': 0,
        'sync_completed': 0,
        'sync_failed': 0,
        'backup_created': 0,
        'errors': defaultdict(int),
        'avg_sync_duration': 0,
        'task_distribution': defaultdict(int)
    }
    
    total_duration = 0
    duration_count = 0
    
    try:
        with open(log_file, 'r') as f:
            for line in f:
                # è§£ææ—¶é—´æˆ³
                timestamp_match = re.match(r'^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})', line)
                if not timestamp_match:
                    continue
                
                log_time = datetime.strptime(timestamp_match.group(1), '%Y-%m-%d %H:%M:%S')
                if log_time < cutoff_time:
                    continue
                
                # åˆ†ææ—¥å¿—å†…å®¹
                if 'SYNC_START' in line:
                    stats['sync_started'] += 1
                    
                    # æå–ä»»åŠ¡ç±»å‹
                    task_match = re.search(r'(\w+) -> (\w+)', line)
                    if task_match:
                        task_type = f"{task_match.group(1)}_to_{task_match.group(2)}"
                        stats['task_distribution'][task_type] += 1
                
                elif 'SYNC_COMPLETE' in line:
                    stats['sync_completed'] += 1
                    
                    # æå–æŒç»­æ—¶é—´
                    duration_match = re.search(r'Duration: ([\d.]+)s', line)
                    if duration_match:
                        duration = float(duration_match.group(1))
                        total_duration += duration
                        duration_count += 1
                
                elif 'BACKUP_CREATE' in line:
                    stats['backup_created'] += 1
                
                elif 'ERROR' in line:
                    stats['sync_failed'] += 1
                    
                    # åˆ†ç±»é”™è¯¯ç±»å‹
                    if 'ConnectionError' in line:
                        stats['errors']['connection_error'] += 1
                    elif 'TimeoutError' in line:
                        stats['errors']['timeout_error'] += 1
                    elif 'ValueError' in line:
                        stats['errors']['value_error'] += 1
                    else:
                        stats['errors']['other_error'] += 1
    
    except FileNotFoundError:
        print(f"æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return stats
    
    # è®¡ç®—å¹³å‡æŒç»­æ—¶é—´
    if duration_count > 0:
        stats['avg_sync_duration'] = total_duration / duration_count
    
    return stats

# ä½¿ç”¨ç¤ºä¾‹
def print_sync_analysis():
    """æ‰“å°åŒæ­¥åˆ†ææŠ¥å‘Š"""
    stats = analyze_sync_logs(hours=24)
    
    print("=== è¿‡å»24å°æ—¶åŒæ­¥åˆ†ææŠ¥å‘Š ===")
    print(f"åŒæ­¥ä»»åŠ¡å¯åŠ¨: {stats['sync_started']}")
    print(f"åŒæ­¥ä»»åŠ¡å®Œæˆ: {stats['sync_completed']}")
    print(f"åŒæ­¥ä»»åŠ¡å¤±è´¥: {stats['sync_failed']}")
    print(f"å¤‡ä»½ä»»åŠ¡åˆ›å»º: {stats['backup_created']}")
    print(f"å¹³å‡åŒæ­¥æ—¶é—´: {stats['avg_sync_duration']:.2f}ç§’")
    
    if stats['sync_started'] > 0:
        success_rate = stats['sync_completed'] / stats['sync_started'] * 100
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
    
    print("\nä»»åŠ¡ç±»å‹åˆ†å¸ƒ:")
    for task_type, count in stats['task_distribution'].items():
        print(f"  {task_type}: {count}")
    
    if stats['errors']:
        print("\né”™è¯¯ç±»å‹åˆ†å¸ƒ:")
        for error_type, count in stats['errors'].items():
            print(f"  {error_type}: {count}")

# è¿è¡Œåˆ†æ
print_sync_analysis()
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### å¸¸è§é—®é¢˜FAQ

**Q: å¦‚ä½•ä¼˜åŒ–åŒæ­¥æ€§èƒ½ï¼Ÿ**
A: 1) å¢åŠ å¹¶å‘ä»»åŠ¡æ•° 2) å¯ç”¨å‹ç¼© 3) è°ƒæ•´æ‰¹å¤„ç†å¤§å° 4) ä½¿ç”¨SSDå­˜å‚¨

**Q: å¤‡ä»½æ–‡ä»¶å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ**
A: 1) å¯ç”¨å‹ç¼© 2) ä½¿ç”¨å¢é‡å¤‡ä»½ 3) å®šæœŸæ¸…ç†æ—§å¤‡ä»½ 4) åˆ†ç‰‡å­˜å‚¨

**Q: å¦‚ä½•ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶æ€ï¼Ÿ**
A: 1) ä½¿ç”¨CLI statuså‘½ä»¤ 2) é›†æˆPrometheus 3) é…ç½®å‘Šè­¦è§„åˆ™ 4) æŸ¥çœ‹æ—¥å¿—åˆ†æ

**Q: æ¢å¤é€Ÿåº¦å¤ªæ…¢ï¼Ÿ**
A: 1) æ£€æŸ¥ç£ç›˜I/Oæ€§èƒ½ 2) å¢åŠ æ¢å¤å¹¶å‘æ•° 3) ä½¿ç”¨æœ¬åœ°å­˜å‚¨ 4) ä¼˜åŒ–ç½‘ç»œè¿æ¥

### è·å–å¸®åŠ©

- **CLIå¸®åŠ©**: `python tradingview/sync_backup_cli.py --help`
- **é…ç½®æ–‡æ¡£**: æŸ¥çœ‹ `sync_backup_config.yaml` æ³¨é‡Š
- **æ—¥å¿—æ–‡ä»¶**: æ£€æŸ¥ `logs/sync_backup.log`
- **å¥åº·æ£€æŸ¥**: è¿è¡Œ `python tradingview/sync_backup_cli.py test`

---

*æœ¬æŒ‡å—æ¶µç›–äº†TradingViewæ•°æ®åŒæ­¥å’Œå¤‡ä»½ç³»ç»Ÿçš„å®Œæ•´ä½¿ç”¨æ–¹æ³•ã€‚å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒæ•…éšœæ’é™¤ç« èŠ‚æˆ–æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—ã€‚*