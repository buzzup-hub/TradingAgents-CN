#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
TradingViewæ•°æ®æºæ¨¡å—å®Œæ•´é›†æˆæµ‹è¯•å¥—ä»¶
éªŒè¯æ‰€æœ‰å¢å¼ºåŠŸèƒ½çš„é›†æˆå’Œæ€§èƒ½è¡¨ç°
"""

import asyncio
import time
import json
import random
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum, auto
import logging
import traceback

# å¯¼å…¥æ‰€æœ‰å¢å¼ºæ¨¡å—
from .enhanced_client import EnhancedTradingViewClient, ConnectionState
from .data_quality_monitor import DataQualityEngine, QualityLevel
from .connection_health import ConnectionHealthMonitor, HealthStatus
from .performance_optimizer import PerformanceOptimizer, IntelligentCache, ConnectionPool
from .fault_recovery import FaultRecoveryManager, FaultType, RecoveryStrategy, BackupDataSource
from .trading_integration import TradingCoreIntegrationManager, TradingViewDataConverter
from .realtime_adapter import AdvancedRealtimeAdapter, SubscriptionType
from .system_monitor import SystemMonitor, SystemStatus, AlertLevel

from config.logging_config import get_logger

logger = get_logger(__name__)


class TestStatus(Enum):
    """æµ‹è¯•çŠ¶æ€"""
    PENDING = auto()
    RUNNING = auto()
    PASSED = auto()
    FAILED = auto()
    SKIPPED = auto()


class TestCategory(Enum):
    """æµ‹è¯•åˆ†ç±»"""
    UNIT = auto()           # å•å…ƒæµ‹è¯•
    INTEGRATION = auto()    # é›†æˆæµ‹è¯•
    PERFORMANCE = auto()    # æ€§èƒ½æµ‹è¯•
    STRESS = auto()         # å‹åŠ›æµ‹è¯•
    FAULT = auto()          # æ•…éšœæµ‹è¯•


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœ"""
    test_name: str
    category: TestCategory
    status: TestStatus
    duration_ms: float
    error_message: str = ""
    details: Dict[str, Any] = None
    timestamp: float = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()
        if self.details is None:
            self.details = {}


class IntegrationTestSuite:
    """é›†æˆæµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        # æµ‹è¯•ç»„ä»¶
        self.enhanced_client: Optional[EnhancedTradingViewClient] = None
        self.data_quality_engine: Optional[DataQualityEngine] = None
        self.connection_monitor: Optional[ConnectionHealthMonitor] = None
        self.performance_optimizer: Optional[PerformanceOptimizer] = None
        self.fault_recovery_manager: Optional[FaultRecoveryManager] = None
        self.integration_manager: Optional[TradingCoreIntegrationManager] = None
        self.realtime_adapter: Optional[AdvancedRealtimeAdapter] = None
        self.system_monitor: Optional[SystemMonitor] = None
        
        # æµ‹è¯•ç»“æœ
        self.test_results: List[TestResult] = []
        self.test_stats = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,  
            'skipped_tests': 0,
            'total_duration_ms': 0.0
        }
        
        # æµ‹è¯•é…ç½®
        self.test_config = {
            'timeout_seconds': 30,
            'max_retry_attempts': 3,
            'test_symbols': ['BTC/USDT', 'ETH/USDT', 'XAU/USD'],
            'stress_test_duration': 60,
            'performance_threshold_ms': 1000,
            'quality_threshold': 0.8,
            'health_threshold': 0.8
        }
        
    async def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        try:
            logger.info("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´é›†æˆæµ‹è¯•å¥—ä»¶...")
            start_time = time.time()
            
            # 1. åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
            await self._setup_test_environment()
            
            # 2. è¿è¡Œå•å…ƒæµ‹è¯•
            await self._run_unit_tests()
            
            # 3. è¿è¡Œé›†æˆæµ‹è¯•
            await self._run_integration_tests()
            
            # 4. è¿è¡Œæ€§èƒ½æµ‹è¯•
            await self._run_performance_tests()
            
            # 5. è¿è¡Œæ•…éšœæµ‹è¯•
            await self._run_fault_tests()
            
            # 6. è¿è¡Œå‹åŠ›æµ‹è¯•
            await self._run_stress_tests()
            
            # 7. æ¸…ç†æµ‹è¯•ç¯å¢ƒ
            await self._cleanup_test_environment()
            
            # 8. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            total_duration = (time.time() - start_time) * 1000
            self.test_stats['total_duration_ms'] = total_duration
            
            test_report = self._generate_test_report()
            
            logger.info(f"âœ… é›†æˆæµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.1f}ms")
            return test_report
            
        except Exception as e:
            logger.error(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            return {'error': str(e), 'traceback': traceback.format_exc()}
    
    async def _setup_test_environment(self) -> None:
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        try:
            logger.info("è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
            
            # åˆå§‹åŒ–å¢å¼ºå®¢æˆ·ç«¯
            self.enhanced_client = EnhancedTradingViewClient()
            
            # åˆå§‹åŒ–æ•°æ®è´¨é‡å¼•æ“
            self.data_quality_engine = DataQualityEngine()
            
            # åˆå§‹åŒ–è¿æ¥å¥åº·ç›‘æ§
            self.connection_monitor = ConnectionHealthMonitor()
            await self.connection_monitor.start_monitoring()
            
            # åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–å™¨
            self.performance_optimizer = PerformanceOptimizer()
            await self.performance_optimizer.initialize()
            
            # åˆå§‹åŒ–æ•…éšœæ¢å¤ç®¡ç†å™¨
            self.fault_recovery_manager = FaultRecoveryManager()
            await self.fault_recovery_manager.start()
            
            # åˆå§‹åŒ–é›†æˆç®¡ç†å™¨
            self.integration_manager = TradingCoreIntegrationManager()
            await self.integration_manager.initialize_integration()
            
            # åˆå§‹åŒ–å®æ—¶é€‚é…å™¨
            self.realtime_adapter = AdvancedRealtimeAdapter()
            await self.realtime_adapter.initialize()
            
            # åˆå§‹åŒ–ç³»ç»Ÿç›‘æ§
            self.system_monitor = SystemMonitor()
            components = {
                'enhanced_client': self.enhanced_client,
                'data_quality_engine': self.data_quality_engine,
                'connection_monitor': self.connection_monitor,
                'performance_optimizer': self.performance_optimizer,
                'fault_recovery_manager': self.fault_recovery_manager,
                'integration_manager': self.integration_manager,
                'realtime_adapter': self.realtime_adapter
            }
            await self.system_monitor.initialize(components)
            
            logger.info("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            raise
    
    async def _cleanup_test_environment(self) -> None:
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            logger.info("æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
            
            # å…³é—­æ‰€æœ‰ç»„ä»¶
            if self.system_monitor:
                await self.system_monitor.shutdown()
            
            if self.realtime_adapter:
                await self.realtime_adapter.shutdown()
            
            if self.integration_manager:
                # integration_manager æ²¡æœ‰ shutdown æ–¹æ³•ï¼Œè·³è¿‡
                pass
            
            if self.fault_recovery_manager:
                await self.fault_recovery_manager.stop()
            
            if self.performance_optimizer:
                await self.performance_optimizer.shutdown()
            
            if self.connection_monitor:
                await self.connection_monitor.stop_monitoring()
            
            if self.enhanced_client:
                await self.enhanced_client.disconnect()
            
            logger.info("âœ… æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âš ï¸ æµ‹è¯•ç¯å¢ƒæ¸…ç†å¤±è´¥: {e}")
    
    async def _run_unit_tests(self) -> None:
        """è¿è¡Œå•å…ƒæµ‹è¯•"""
        logger.info("ğŸ§ª è¿è¡Œå•å…ƒæµ‹è¯•...")
        
        # æµ‹è¯•æ•°æ®è½¬æ¢å™¨
        await self._test_data_converter()
        
        # æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ
        await self._test_intelligent_cache()
        
        # æµ‹è¯•è¿æ¥æ± 
        await self._test_connection_pool()
        
        # æµ‹è¯•æ–­è·¯å™¨
        await self._test_circuit_breaker()
        
        # æµ‹è¯•æ•°æ®è´¨é‡è¯„ä¼°
        await self._test_data_quality_evaluation()
    
    async def _test_data_converter(self) -> None:
        """æµ‹è¯•æ•°æ®è½¬æ¢å™¨"""
        test_name = "æ•°æ®è½¬æ¢å™¨æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            converter = TradingViewDataConverter()
            
            # æµ‹è¯•æ­£å¸¸æ•°æ®è½¬æ¢
            tv_data = {
                'time': time.time(),
                'open': 50000.0,
                'high': 51000.0,
                'low': 49500.0,
                'close': 50500.0,
                'volume': 1000.0
            }
            
            market_data = converter.convert_kline_to_market_data(tv_data, "BTC/USDT")
            assert market_data is not None, "æ­£å¸¸æ•°æ®è½¬æ¢å¤±è´¥"
            assert market_data.symbol == "BTC/USDT", "ç¬¦å·è½¬æ¢é”™è¯¯"
            assert market_data.close == 50500.0, "ä»·æ ¼è½¬æ¢é”™è¯¯"
            
            # æµ‹è¯•å¼‚å¸¸æ•°æ®å¤„ç†
            invalid_data = {'invalid': 'data'}
            result = converter.convert_kline_to_market_data(invalid_data, "BTC/USDT")
            assert result is None, "å¼‚å¸¸æ•°æ®åº”è¯¥è¿”å›None"
            
            # æµ‹è¯•è½¬æ¢ç»Ÿè®¡
            stats = converter.get_conversion_stats()
            assert 'success_rate' in stats, "ç¼ºå°‘è½¬æ¢ç»Ÿè®¡"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.UNIT, TestStatus.PASSED, duration_ms)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.UNIT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_intelligent_cache(self) -> None:
        """æµ‹è¯•æ™ºèƒ½ç¼“å­˜"""
        test_name = "æ™ºèƒ½ç¼“å­˜æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            cache = IntelligentCache(max_size=100)
            await cache.start()
            
            try:
                # æµ‹è¯•åŸºæœ¬ç¼“å­˜æ“ä½œ
                test_key = "test_key"
                test_value = {"data": "test_value"}
                
                # æµ‹è¯•è®¾ç½®å’Œè·å–
                result = await cache.put(test_key, test_value)
                assert result is True, "ç¼“å­˜è®¾ç½®å¤±è´¥"
                
                cached_value = cache.get(test_key)
                assert cached_value is not None, "ç¼“å­˜è·å–å¤±è´¥"
                assert cached_value["data"] == "test_value", "ç¼“å­˜å€¼ä¸åŒ¹é…"
                
                # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
                stats = cache.get_cache_stats()
                assert stats['hits'] > 0, "ç¼“å­˜å‘½ä¸­ç»Ÿè®¡é”™è¯¯"
                assert stats['entry_count'] > 0, "ç¼“å­˜æ¡ç›®ç»Ÿè®¡é”™è¯¯"
                
                # æµ‹è¯•ç¼“å­˜æ¸…ç†
                cache.clear()
                assert cache.get(test_key) is None, "ç¼“å­˜æ¸…ç†å¤±è´¥"
                
                duration_ms = (time.perf_counter() - start_time) * 1000
                self._record_test_result(test_name, TestCategory.UNIT, TestStatus.PASSED, duration_ms)
                
            finally:
                await cache.stop()
                
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.UNIT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_connection_pool(self) -> None:
        """æµ‹è¯•è¿æ¥æ± """
        test_name = "è¿æ¥æ± æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # æ¨¡æ‹Ÿè¿æ¥å·¥å‚
            async def mock_connection_factory():
                await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿè¿æ¥åˆ›å»ºæ—¶é—´
                return f"mock_connection_{time.time()}"
            
            pool = ConnectionPool(min_connections=2, max_connections=10)
            await pool.initialize(mock_connection_factory)
            
            try:
                # æµ‹è¯•è·å–è¿æ¥
                connection = await pool.get_connection()
                assert connection is not None, "è·å–è¿æ¥å¤±è´¥"
                
                # æµ‹è¯•å½’è¿˜è¿æ¥
                result = await pool.return_connection(connection)
                assert result is True, "å½’è¿˜è¿æ¥å¤±è´¥"
                
                # æµ‹è¯•è¿æ¥æ± ç»Ÿè®¡
                stats = pool.get_pool_stats()
                assert 'current_active' in stats, "ç¼ºå°‘è¿æ¥æ± ç»Ÿè®¡"
                assert 'total_created' in stats, "ç¼ºå°‘è¿æ¥åˆ›å»ºç»Ÿè®¡"
                
                duration_ms = (time.perf_counter() - start_time) * 1000
                self._record_test_result(test_name, TestCategory.UNIT, TestStatus.PASSED, duration_ms)
                
            finally:
                await pool.shutdown()
                
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.UNIT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_circuit_breaker(self) -> None:
        """æµ‹è¯•æ–­è·¯å™¨"""
        test_name = "æ–­è·¯å™¨æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            from .fault_recovery import CircuitBreaker
            
            circuit_breaker = CircuitBreaker(failure_threshold=3, timeout_seconds=1)
            
            # æµ‹è¯•æ­£å¸¸è°ƒç”¨
            def success_func():
                return "success"
            
            result = circuit_breaker.call(success_func)
            assert result == "success", "æ­£å¸¸è°ƒç”¨å¤±è´¥"
            
            # æµ‹è¯•å¤±è´¥è°ƒç”¨
            def failure_func():
                raise Exception("test failure")
            
            # è§¦å‘æ–­è·¯å™¨æ‰“å¼€
            for _ in range(4):
                try:
                    circuit_breaker.call(failure_func)
                except:
                    pass
            
            # æ–­è·¯å™¨åº”è¯¥å·²æ‰“å¼€
            assert circuit_breaker.state == "OPEN", "æ–­è·¯å™¨æœªæ‰“å¼€"
            
            # æµ‹è¯•æ–­è·¯å™¨ç»Ÿè®¡
            stats = circuit_breaker.get_stats()
            assert stats['total_failures'] >= 3, "å¤±è´¥ç»Ÿè®¡é”™è¯¯"
            assert stats['state'] == "OPEN", "æ–­è·¯å™¨çŠ¶æ€é”™è¯¯"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.UNIT, TestStatus.PASSED, duration_ms)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.UNIT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_data_quality_evaluation(self) -> None:
        """æµ‹è¯•æ•°æ®è´¨é‡è¯„ä¼°"""
        test_name = "æ•°æ®è´¨é‡è¯„ä¼°æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            engine = self.data_quality_engine
            
            # æµ‹è¯•é«˜è´¨é‡æ•°æ®
            good_data = [{
                'time': time.time(),
                'open': 50000.0,
                'high': 51000.0,
                'low': 49500.0,
                'close': 50500.0,
                'volume': 1000.0
            }]
            
            metrics = await engine.evaluate_data_quality("BTC/USDT", good_data)
            assert metrics.overall_quality_score > 0.8, f"é«˜è´¨é‡æ•°æ®è¯„åˆ†è¿‡ä½: {metrics.overall_quality_score}"
            assert metrics.quality_level in [QualityLevel.EXCELLENT, QualityLevel.GOOD], "è´¨é‡ç­‰çº§é”™è¯¯"
            
            # æµ‹è¯•ä½è´¨é‡æ•°æ®
            bad_data = [{
                'time': time.time(),
                'open': -1.0,  # è´Ÿä»·æ ¼
                'high': 0.0,   # é›¶ä»·æ ¼
                'low': 100.0,  # é€»è¾‘é”™è¯¯çš„ä»·æ ¼å…³ç³»
                'close': 50.0
            }]
            
            metrics = await engine.evaluate_data_quality("BTC/USDT", bad_data)
            assert metrics.overall_quality_score < 0.5, f"ä½è´¨é‡æ•°æ®è¯„åˆ†è¿‡é«˜: {metrics.overall_quality_score}"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.UNIT, TestStatus.PASSED, duration_ms)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.UNIT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _run_integration_tests(self) -> None:
        """è¿è¡Œé›†æˆæµ‹è¯•"""
        logger.info("ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•...")
        
        # æµ‹è¯•ç«¯åˆ°ç«¯æ•°æ®æµ
        await self._test_end_to_end_data_flow()
        
        # æµ‹è¯•ç»„ä»¶é—´é€šä¿¡
        await self._test_component_communication()
        
        # æµ‹è¯•ç³»ç»Ÿç›‘æ§é›†æˆ
        await self._test_system_monitoring_integration()
        
        # æµ‹è¯•é…ç½®ç®¡ç†é›†æˆ
        await self._test_configuration_integration()
    
    async def _test_end_to_end_data_flow(self) -> None:
        """æµ‹è¯•ç«¯åˆ°ç«¯æ•°æ®æµ"""
        test_name = "ç«¯åˆ°ç«¯æ•°æ®æµæµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # æ¨¡æ‹Ÿå®Œæ•´çš„æ•°æ®æµï¼šTradingView -> æ•°æ®è´¨é‡ -> è½¬æ¢ -> å®æ—¶é€‚é…
            
            # 1. æ¨¡æ‹ŸTradingViewæ•°æ®
            tv_data = {
                'time': time.time(),
                'open': 50000.0,
                'high': 51000.0,
                'low': 49500.0,
                'close': 50500.0,
                'volume': 1000.0
            }
            
            # 2. æ•°æ®è´¨é‡è¯„ä¼°
            quality_metrics = await self.data_quality_engine.evaluate_data_quality("BTC/USDT", [tv_data])
            assert quality_metrics.overall_quality_score > 0.7, "æ•°æ®è´¨é‡è¯„ä¼°å¤±è´¥"
            
            # 3. æ•°æ®æ ¼å¼è½¬æ¢
            converter = TradingViewDataConverter()
            market_data = converter.convert_kline_to_market_data(tv_data, "BTC/USDT")
            assert market_data is not None, "æ•°æ®è½¬æ¢å¤±è´¥"
            
            # 4. å®æ—¶é€‚é…å™¨å¤„ç†
            success = await self.realtime_adapter.process_realtime_data(
                "BTC/USDT", tv_data, SubscriptionType.KLINE_15M
            )
            assert success is True, "å®æ—¶é€‚é…å™¨å¤„ç†å¤±è´¥"
            
            # 5. éªŒè¯æ•°æ®å®Œæ•´æ€§
            assert market_data.symbol == "BTC/USDT", "ç¬¦å·ä¸åŒ¹é…"
            assert market_data.close == 50500.0, "ä»·æ ¼ä¸åŒ¹é…"
            assert market_data.quality_score > 0.7, "è´¨é‡åˆ†æ•°è¿‡ä½"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.INTEGRATION, TestStatus.PASSED, duration_ms)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.INTEGRATION, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_component_communication(self) -> None:
        """æµ‹è¯•ç»„ä»¶é—´é€šä¿¡"""
        test_name = "ç»„ä»¶é—´é€šä¿¡æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # æµ‹è¯•æ•…éšœæ¢å¤ç®¡ç†å™¨ä¸å…¶ä»–ç»„ä»¶çš„é€šä¿¡
            
            # 1. æ³¨å†Œç»„ä»¶å¥åº·æ£€æŸ¥
            async def mock_health_check():
                return {
                    'response_time_ms': 100,
                    'success_rate': 0.95,
                    'data_quality_score': 0.9
                }
            
            self.fault_recovery_manager.register_component('test_component', mock_health_check)
            
            # 2. ç­‰å¾…å¥åº·æ£€æŸ¥æ‰§è¡Œ
            await asyncio.sleep(2)
            
            # 3. éªŒè¯å¥åº·æŠ¥å‘Š
            health_report = self.fault_recovery_manager.get_system_health_report()
            assert 'component_health' in health_report, "ç¼ºå°‘ç»„ä»¶å¥åº·ä¿¡æ¯"
            
            # 4. æµ‹è¯•ç³»ç»Ÿç›‘æ§æ•°æ®æ”¶é›†
            dashboard = self.system_monitor.get_system_dashboard()
            assert 'system_overview' in dashboard, "ç¼ºå°‘ç³»ç»Ÿæ¦‚è§ˆ"
            assert 'component_summary' in dashboard, "ç¼ºå°‘ç»„ä»¶æ‘˜è¦"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.INTEGRATION, TestStatus.PASSED, duration_ms)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.INTEGRATION, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_system_monitoring_integration(self) -> None:
        """æµ‹è¯•ç³»ç»Ÿç›‘æ§é›†æˆ"""
        test_name = "ç³»ç»Ÿç›‘æ§é›†æˆæµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # ç­‰å¾…ç›‘æ§æ”¶é›†æ•°æ®
            await asyncio.sleep(3)
            
            # è·å–ä»ªè¡¨æ¿æ•°æ®
            dashboard = self.system_monitor.get_system_dashboard()
            
            # éªŒè¯åŸºæœ¬ç»“æ„
            required_sections = [
                'system_overview', 'component_summary', 'performance_metrics',
                'data_metrics', 'fault_metrics', 'monitoring_stats'
            ]
            
            for section in required_sections:
                assert section in dashboard, f"ç¼ºå°‘ä»ªè¡¨æ¿éƒ¨åˆ†: {section}"
            
            # éªŒè¯ç³»ç»Ÿæ¦‚è§ˆ
            system_overview = dashboard['system_overview']
            assert 'status' in system_overview, "ç¼ºå°‘ç³»ç»ŸçŠ¶æ€"
            assert 'health_score' in system_overview, "ç¼ºå°‘å¥åº·åˆ†æ•°"
            assert 'uptime_seconds' in system_overview, "ç¼ºå°‘è¿è¡Œæ—¶é—´"
            
            # éªŒè¯ç»„ä»¶æ‘˜è¦
            component_summary = dashboard['component_summary']
            assert component_summary['total_components'] > 0, "ç»„ä»¶æ•°é‡ä¸º0"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.INTEGRATION, TestStatus.PASSED, duration_ms)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.INTEGRATION, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_configuration_integration(self) -> None:
        """æµ‹è¯•é…ç½®ç®¡ç†é›†æˆ"""
        test_name = "é…ç½®ç®¡ç†é›†æˆæµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # æµ‹è¯•å„ç»„ä»¶çš„é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½
            
            # 1. éªŒè¯æ€§èƒ½ä¼˜åŒ–å™¨é…ç½®
            if self.performance_optimizer:
                perf_stats = self.performance_optimizer.get_comprehensive_stats()
                assert 'cache_stats' in perf_stats, "ç¼“å­˜ç»Ÿè®¡ç¼ºå¤±"
                assert 'pool_stats' in perf_stats, "è¿æ¥æ± ç»Ÿè®¡ç¼ºå¤±"
            
            # 2. éªŒè¯æ•…éšœæ¢å¤ç®¡ç†å™¨é…ç½®
            if self.fault_recovery_manager:
                health_report = self.fault_recovery_manager.get_system_health_report()
                assert 'recovery_stats' in health_report, "æ¢å¤ç»Ÿè®¡ç¼ºå¤±"
            
            # 3. éªŒè¯å®æ—¶é€‚é…å™¨é…ç½®
            if self.realtime_adapter:
                adapter_stats = self.realtime_adapter.get_comprehensive_stats()
                assert 'subscription_status' in adapter_stats, "è®¢é˜…çŠ¶æ€ç¼ºå¤±"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.INTEGRATION, TestStatus.PASSED, duration_ms)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.INTEGRATION, TestStatus.FAILED, duration_ms, str(e))
    
    async def _run_performance_tests(self) -> None:
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        logger.info("âš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•...")
        
        # æµ‹è¯•æ•°æ®å¤„ç†æ€§èƒ½
        await self._test_data_processing_performance()
        
        # æµ‹è¯•ç¼“å­˜æ€§èƒ½
        await self._test_cache_performance()
        
        # æµ‹è¯•å¹¶å‘å¤„ç†æ€§èƒ½
        await self._test_concurrent_performance()
        
        # æµ‹è¯•å†…å­˜ä½¿ç”¨
        await self._test_memory_usage()
    
    async def _test_data_processing_performance(self) -> None:
        """æµ‹è¯•æ•°æ®å¤„ç†æ€§èƒ½"""
        test_name = "æ•°æ®å¤„ç†æ€§èƒ½æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            converter = TradingViewDataConverter()
            data_count = 1000
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            test_data = []
            for i in range(data_count):
                test_data.append({
                    'time': time.time() + i,
                    'open': 50000.0 + random.uniform(-100, 100),
                    'high': 51000.0 + random.uniform(-100, 100),
                    'low': 49500.0 + random.uniform(-100, 100),
                    'close': 50500.0 + random.uniform(-100, 100),
                    'volume': 1000.0 + random.uniform(-100, 100)
                })
            
            # æµ‹è¯•è½¬æ¢æ€§èƒ½
            conversion_start = time.perf_counter()
            successful_conversions = 0
            
            for data in test_data:
                result = converter.convert_kline_to_market_data(data, "BTC/USDT")
                if result:
                    successful_conversions += 1
            
            conversion_time = (time.perf_counter() - conversion_start) * 1000
            avg_conversion_time = conversion_time / data_count
            
            # éªŒè¯æ€§èƒ½æŒ‡æ ‡
            assert avg_conversion_time < 1.0, f"å¹³å‡è½¬æ¢æ—¶é—´è¿‡é•¿: {avg_conversion_time:.2f}ms"
            assert successful_conversions / data_count > 0.95, f"è½¬æ¢æˆåŠŸç‡è¿‡ä½: {successful_conversions/data_count:.1%}"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'data_count': data_count,
                'total_conversion_time_ms': conversion_time,
                'avg_conversion_time_ms': avg_conversion_time,
                'success_rate': successful_conversions / data_count
            }
            
            self._record_test_result(test_name, TestCategory.PERFORMANCE, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.PERFORMANCE, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_cache_performance(self) -> None:
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        test_name = "ç¼“å­˜æ€§èƒ½æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            cache = IntelligentCache(max_size=1000)
            await cache.start()
            
            try:
                # æµ‹è¯•å¤§é‡å†™å…¥æ“ä½œ
                write_count = 1000
                write_start = time.time()
                
                for i in range(write_count):
                    await cache.put(f"key_{i}", f"value_{i}")
                
                write_time = (time.time() - write_start) * 1000
                avg_write_time = write_time / write_count
                
                # æµ‹è¯•å¤§é‡è¯»å–æ“ä½œ
                read_start = time.time()
                hits = 0
                
                for i in range(write_count):
                    value = cache.get(f"key_{i}")
                    if value:
                        hits += 1
                
                read_time = (time.time() - read_start) * 1000
                avg_read_time = read_time / write_count
                hit_rate = hits / write_count
                
                # éªŒè¯æ€§èƒ½æŒ‡æ ‡
                assert avg_write_time < 0.1, f"å¹³å‡å†™å…¥æ—¶é—´è¿‡é•¿: {avg_write_time:.3f}ms"
                assert avg_read_time < 0.05, f"å¹³å‡è¯»å–æ—¶é—´è¿‡é•¿: {avg_read_time:.3f}ms"
                assert hit_rate > 0.99, f"ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {hit_rate:.1%}"
                
                duration_ms = (time.perf_counter() - start_time) * 1000
                details = {
                    'write_count': write_count,
                    'avg_write_time_ms': avg_write_time,
                    'avg_read_time_ms': avg_read_time,
                    'hit_rate': hit_rate
                }
                
                self._record_test_result(test_name, TestCategory.PERFORMANCE, TestStatus.PASSED, duration_ms, details=details)
                
            finally:
                await cache.stop()
                
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.PERFORMANCE, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_concurrent_performance(self) -> None:
        """æµ‹è¯•å¹¶å‘å¤„ç†æ€§èƒ½"""
        test_name = "å¹¶å‘å¤„ç†æ€§èƒ½æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # åˆ›å»ºå¤šä¸ªå¹¶å‘ä»»åŠ¡
            concurrent_tasks = 100
            tasks = []
            
            async def data_processing_task(task_id: int):
                """å•ä¸ªæ•°æ®å¤„ç†ä»»åŠ¡"""
                converter = TradingViewDataConverter()
                
                for i in range(10):  # æ¯ä¸ªä»»åŠ¡å¤„ç†10æ¡æ•°æ®
                    data = {
                        'time': time.time() + i,
                        'open': 50000.0 + random.uniform(-100, 100),
                        'high': 51000.0 + random.uniform(-100, 100),
                        'low': 49500.0 + random.uniform(-100, 100),
                        'close': 50500.0 + random.uniform(-100, 100),
                        'volume': 1000.0
                    }
                    
                    result = converter.convert_kline_to_market_data(data, f"SYMBOL_{task_id}")
                    if not result:
                        raise Exception(f"Task {task_id} conversion failed")
                
                return task_id
            
            # å¯åŠ¨æ‰€æœ‰å¹¶å‘ä»»åŠ¡
            concurrent_start = time.time()
            
            for i in range(concurrent_tasks):
                task = asyncio.create_task(data_processing_task(i))
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            concurrent_time = (time.time() - concurrent_start) * 1000
            
            # ç»Ÿè®¡ç»“æœ
            successful_tasks = sum(1 for r in results if not isinstance(r, Exception))
            failed_tasks = len(results) - successful_tasks
            
            # éªŒè¯å¹¶å‘æ€§èƒ½
            assert concurrent_time < 5000, f"å¹¶å‘å¤„ç†æ—¶é—´è¿‡é•¿: {concurrent_time:.1f}ms"
            assert successful_tasks / concurrent_tasks > 0.95, f"å¹¶å‘æˆåŠŸç‡è¿‡ä½: {successful_tasks/concurrent_tasks:.1%}"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'concurrent_tasks': concurrent_tasks,
                'concurrent_time_ms': concurrent_time,
                'successful_tasks': successful_tasks,
                'failed_tasks': failed_tasks,
                'success_rate': successful_tasks / concurrent_tasks
            }
            
            self._record_test_result(test_name, TestCategory.PERFORMANCE, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.PERFORMANCE, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_memory_usage(self) -> None:
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        test_name = "å†…å­˜ä½¿ç”¨æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            import psutil
            import gc
            
            # è®°å½•åˆå§‹å†…å­˜ä½¿ç”¨
            process = psutil.Process()
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # åˆ›å»ºå¤§é‡æ•°æ®è¿›è¡Œå¤„ç†
            converter = TradingViewDataConverter()
            data_count = 10000
            processed_data = []
            
            for i in range(data_count):
                data = {
                    'time': time.time() + i,
                    'open': 50000.0 + random.uniform(-100, 100),
                    'high': 51000.0 + random.uniform(-100, 100),
                    'low': 49500.0 + random.uniform(-100, 100),
                    'close': 50500.0 + random.uniform(-100, 100),
                    'volume': 1000.0
                }
                
                result = converter.convert_kline_to_market_data(data, "BTC/USDT")
                if result:
                    processed_data.append(result)
            
            # è®°å½•å³°å€¼å†…å­˜ä½¿ç”¨
            peak_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # æ¸…ç†æ•°æ®
            processed_data.clear()
            gc.collect()
            
            # è®°å½•æ¸…ç†åå†…å­˜ä½¿ç”¨
            final_memory = process.memory_info().rss / 1024 / 1024  # MB
            
            # è®¡ç®—å†…å­˜ä½¿ç”¨æŒ‡æ ‡
            memory_increase = peak_memory - initial_memory
            memory_per_item = memory_increase / data_count * 1024  # KB per item
            memory_cleanup_ratio = (peak_memory - final_memory) / memory_increase if memory_increase > 0 else 0
            
            # éªŒè¯å†…å­˜ä½¿ç”¨åˆç†æ€§
            assert memory_per_item < 1.0, f"å•é¡¹å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory_per_item:.2f}KB"
            assert memory_cleanup_ratio > 0.8, f"å†…å­˜æ¸…ç†æ•ˆæœä¸ä½³: {memory_cleanup_ratio:.1%}"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'data_count': data_count,
                'initial_memory_mb': initial_memory,
                'peak_memory_mb': peak_memory,
                'final_memory_mb': final_memory,
                'memory_increase_mb': memory_increase,
                'memory_per_item_kb': memory_per_item,
                'memory_cleanup_ratio': memory_cleanup_ratio
            }
            
            self._record_test_result(test_name, TestCategory.PERFORMANCE, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.PERFORMANCE, TestStatus.FAILED, duration_ms, str(e))
    
    async def _run_fault_tests(self) -> None:
        """è¿è¡Œæ•…éšœæµ‹è¯•"""
        logger.info("ğŸ›¡ï¸ è¿è¡Œæ•…éšœæµ‹è¯•...")
        
        # æµ‹è¯•æ•…éšœæ£€æµ‹
        await self._test_fault_detection()
        
        # æµ‹è¯•æ•…éšœæ¢å¤
        await self._test_fault_recovery()
        
        # æµ‹è¯•æ–­è·¯å™¨
        await self._test_circuit_breaker_fault_handling()
        
        # æµ‹è¯•å¤‡ç”¨æ•°æ®æºåˆ‡æ¢
        await self._test_backup_source_switching()
    
    async def _test_fault_detection(self) -> None:
        """æµ‹è¯•æ•…éšœæ£€æµ‹"""
        test_name = "æ•…éšœæ£€æµ‹æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # æ¨¡æ‹Ÿæ•…éšœæ¡ä»¶
            fault_metrics = {
                'component': 'test_component',
                'response_time_ms': 6000,  # è¶…è¿‡5ç§’é˜ˆå€¼
                'success_rate': 0.3,       # ä½äº80%é˜ˆå€¼
                'data_quality_score': 0.4  # ä½äº50%é˜ˆå€¼
            }
            
            # è§¦å‘æ•…éšœæ£€æµ‹
            detected_faults = await self.fault_recovery_manager.fault_detector.check_for_faults(fault_metrics)
            
            # éªŒè¯æ•…éšœæ£€æµ‹ç»“æœ
            assert len(detected_faults) > 0, "æœªæ£€æµ‹åˆ°æ•…éšœ"
            
            # éªŒè¯æ•…éšœç±»å‹
            fault_types = [fault.fault_type for fault in detected_faults]
            expected_types = [FaultType.DATA_TIMEOUT, FaultType.SYSTEM_OVERLOAD, FaultType.DATA_CORRUPTION]
            
            for expected_type in expected_types:
                assert expected_type in fault_types, f"æœªæ£€æµ‹åˆ°é¢„æœŸæ•…éšœç±»å‹: {expected_type}"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'detected_faults_count': len(detected_faults),
                'fault_types': [f.fault_type.name for f in detected_faults]
            }
            
            self._record_test_result(test_name, TestCategory.FAULT, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.FAULT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_fault_recovery(self) -> None:
        """æµ‹è¯•æ•…éšœæ¢å¤"""
        test_name = "æ•…éšœæ¢å¤æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            from .fault_recovery import FaultIncident
            
            # åˆ›å»ºæ¨¡æ‹Ÿæ•…éšœ
            incident = FaultIncident(
                incident_id="test_recovery_001",
                fault_type=FaultType.CONNECTION_LOST,
                component="test_component",
                description="æ¨¡æ‹Ÿè¿æ¥ä¸¢å¤±æ•…éšœ",
                severity=3
            )
            
            # è®°å½•æ´»è·ƒæ•…éšœæ•°é‡
            initial_active_incidents = len(self.fault_recovery_manager.active_incidents)
            
            # è§¦å‘æ•…éšœå¤„ç†
            await self.fault_recovery_manager._handle_detected_fault(incident)
            
            # ç­‰å¾…æ¢å¤å°è¯•
            await asyncio.sleep(2)
            
            # éªŒè¯æ•…éšœå·²è¢«è®°å½•
            assert len(self.fault_recovery_manager.active_incidents) > initial_active_incidents, "æ•…éšœæœªè¢«è®°å½•"
            
            # éªŒè¯æ¢å¤ç­–ç•¥å·²è®¾ç½®
            assert incident.recovery_strategy is not None, "æœªè®¾ç½®æ¢å¤ç­–ç•¥"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'incident_id': incident.incident_id,
                'recovery_strategy': incident.recovery_strategy.name if incident.recovery_strategy else None,
                'recovery_attempts': incident.recovery_attempts
            }
            
            self._record_test_result(test_name, TestCategory.FAULT, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.FAULT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_circuit_breaker_fault_handling(self) -> None:
        """æµ‹è¯•æ–­è·¯å™¨æ•…éšœå¤„ç†"""
        test_name = "æ–­è·¯å™¨æ•…éšœå¤„ç†æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            circuit_breaker = self.fault_recovery_manager.get_circuit_breaker("test_component")
            
            # æ¨¡æ‹Ÿè¿ç»­å¤±è´¥
            def failing_function():
                raise Exception("æ¨¡æ‹Ÿå¤±è´¥")
            
            failure_count = 0
            for i in range(10):
                try:
                    circuit_breaker.call(failing_function)
                except:
                    failure_count += 1
            
            # éªŒè¯æ–­è·¯å™¨çŠ¶æ€
            stats = circuit_breaker.get_stats()
            assert stats['state'] == 'OPEN', f"æ–­è·¯å™¨çŠ¶æ€é”™è¯¯: {stats['state']}"
            assert stats['total_failures'] >= 5, f"å¤±è´¥è®¡æ•°é”™è¯¯: {stats['total_failures']}"
            
            # æµ‹è¯•æ–­è·¯å™¨é˜»æ­¢åç»­è°ƒç”¨
            try:
                circuit_breaker.call(lambda: "success")
                assert False, "æ–­è·¯å™¨æœªé˜»æ­¢è°ƒç”¨"
            except Exception as e:
                assert "Circuit breaker is OPEN" in str(e), "æ–­è·¯å™¨é”™è¯¯æ¶ˆæ¯ä¸æ­£ç¡®"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'circuit_breaker_state': stats['state'],
                'total_failures': stats['total_failures'],
                'failure_rate': stats['failure_rate']
            }
            
            self._record_test_result(test_name, TestCategory.FAULT, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.FAULT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_backup_source_switching(self) -> None:
        """æµ‹è¯•å¤‡ç”¨æ•°æ®æºåˆ‡æ¢"""
        test_name = "å¤‡ç”¨æ•°æ®æºåˆ‡æ¢æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # åˆ›å»ºæ¨¡æ‹Ÿå¤‡ç”¨æ•°æ®æº
            async def mock_backup_client():
                return "mock_backup_client"
            
            backup_source = BackupDataSource(
                name="mock_backup",
                priority=1,
                client_factory=mock_backup_client
            )
            
            # æ·»åŠ å¤‡ç”¨æ•°æ®æº
            self.fault_recovery_manager.add_backup_source("test_component", backup_source)
            
            # æ¨¡æ‹Ÿæ•…éšœéœ€è¦åˆ‡æ¢å¤‡ç”¨æº
            from .fault_recovery import FaultIncident
            
            incident = FaultIncident(
                incident_id="backup_test_001",
                fault_type=FaultType.DATA_TIMEOUT,
                component="test_component",
                description="éœ€è¦åˆ‡æ¢å¤‡ç”¨æ•°æ®æº",
                severity=2
            )
            
            # æ‰§è¡Œå¤‡ç”¨æºæ¢å¤
            await self.fault_recovery_manager._fallback_source_recovery(incident)
            
            # éªŒè¯å¤‡ç”¨æºçŠ¶æ€
            backup_stats = backup_source.get_stats()
            assert backup_source.is_active or incident.is_resolved, "å¤‡ç”¨æºåˆ‡æ¢å¤±è´¥"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'backup_source_name': backup_source.name,
                'is_active': backup_source.is_active,
                'incident_resolved': incident.is_resolved
            }
            
            self._record_test_result(test_name, TestCategory.FAULT, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.FAULT, TestStatus.FAILED, duration_ms, str(e))
    
    async def _run_stress_tests(self) -> None:
        """è¿è¡Œå‹åŠ›æµ‹è¯•"""
        logger.info("ğŸ’ª è¿è¡Œå‹åŠ›æµ‹è¯•...")
        
        # æµ‹è¯•é«˜é¢‘æ•°æ®å¤„ç†
        await self._test_high_frequency_data_processing()
        
        # æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§
        await self._test_long_running_stability()
        
        # æµ‹è¯•èµ„æºè€—å°½åœºæ™¯
        await self._test_resource_exhaustion()
    
    async def _test_high_frequency_data_processing(self) -> None:
        """æµ‹è¯•é«˜é¢‘æ•°æ®å¤„ç†"""
        test_name = "é«˜é¢‘æ•°æ®å¤„ç†å‹åŠ›æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # é…ç½®é«˜é¢‘æµ‹è¯•å‚æ•°
            data_rate = 100  # æ¯ç§’100æ¡æ•°æ®
            test_duration = 30  # æµ‹è¯•30ç§’
            total_expected = data_rate * test_duration
            
            processed_count = 0
            error_count = 0
            
            async def data_generator():
                """æ•°æ®ç”Ÿæˆå™¨"""
                nonlocal processed_count, error_count
                
                end_time = time.time() + test_duration
                while time.time() < end_time:
                    try:
                        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                        data = {
                            'time': time.time(),
                            'open': 50000.0 + random.uniform(-100, 100),
                            'high': 51000.0 + random.uniform(-100, 100),
                            'low': 49500.0 + random.uniform(-100, 100),
                            'close': 50500.0 + random.uniform(-100, 100),
                            'volume': 1000.0
                        }
                        
                        # å¤„ç†æ•°æ®
                        success = await self.realtime_adapter.process_realtime_data(
                            "BTC/USDT", data, SubscriptionType.KLINE_15M
                        )
                        
                        if success:
                            processed_count += 1
                        else:
                            error_count += 1
                        
                        # æ§åˆ¶æ•°æ®é¢‘ç‡
                        await asyncio.sleep(1.0 / data_rate)
                        
                    except Exception as e:
                        error_count += 1
                        logger.error(f"æ•°æ®å¤„ç†é”™è¯¯: {e}")
            
            # å¯åŠ¨æ•°æ®ç”Ÿæˆå™¨
            await data_generator()
            
            # éªŒè¯å¤„ç†ç»“æœ
            success_rate = processed_count / (processed_count + error_count) if (processed_count + error_count) > 0 else 0
            processing_rate = processed_count / test_duration
            
            assert success_rate > 0.95, f"é«˜é¢‘å¤„ç†æˆåŠŸç‡è¿‡ä½: {success_rate:.1%}"
            assert processing_rate >= data_rate * 0.9, f"å¤„ç†é€Ÿç‡ä¸è¶³: {processing_rate:.1f}/s (æœŸæœ›: {data_rate}/s)"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'test_duration_s': test_duration,
                'target_data_rate': data_rate,
                'processed_count': processed_count,
                'error_count': error_count,
                'success_rate': success_rate,
                'actual_processing_rate': processing_rate
            }
            
            self._record_test_result(test_name, TestCategory.STRESS, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.STRESS, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_long_running_stability(self) -> None:
        """æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§"""
        test_name = "é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # é…ç½®é•¿æ—¶é—´æµ‹è¯•å‚æ•°
            test_duration = 60  # æµ‹è¯•60ç§’
            check_interval = 5   # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
            
            initial_stats = {
                'system_health': 0,
                'memory_usage': 0,
                'active_connections': 0
            }
            
            # è®°å½•åˆå§‹çŠ¶æ€
            if self.system_monitor:
                dashboard = self.system_monitor.get_system_dashboard()
                initial_stats['system_health'] = dashboard.get('system_overview', {}).get('health_score', 0)
            
            stability_checks = []
            end_time = time.time() + test_duration
            
            # å®šæœŸç¨³å®šæ€§æ£€æŸ¥
            while time.time() < end_time:
                try:
                    check_time = time.time()
                    
                    # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
                    if self.system_monitor:
                        dashboard = self.system_monitor.get_system_dashboard()
                        system_overview = dashboard.get('system_overview', {})
                        
                        check_result = {
                            'timestamp': check_time,
                            'health_score': system_overview.get('health_score', 0),
                            'status': system_overview.get('status', 'UNKNOWN'),
                            'uptime': system_overview.get('uptime_seconds', 0)
                        }
                        
                        stability_checks.append(check_result)
                    
                    await asyncio.sleep(check_interval)
                    
                except Exception as e:
                    logger.error(f"ç¨³å®šæ€§æ£€æŸ¥é”™è¯¯: {e}")
            
            # åˆ†æç¨³å®šæ€§æ•°æ®
            if stability_checks:
                health_scores = [check['health_score'] for check in stability_checks]
                avg_health = sum(health_scores) / len(health_scores)
                min_health = min(health_scores)
                health_variance = sum((h - avg_health) ** 2 for h in health_scores) / len(health_scores)
                
                # éªŒè¯ç¨³å®šæ€§æŒ‡æ ‡
                assert avg_health > 0.7, f"å¹³å‡å¥åº·åˆ†æ•°è¿‡ä½: {avg_health:.2f}"
                assert min_health > 0.5, f"æœ€ä½å¥åº·åˆ†æ•°è¿‡ä½: {min_health:.2f}"
                assert health_variance < 0.1, f"å¥åº·åˆ†æ•°æ³¢åŠ¨è¿‡å¤§: {health_variance:.3f}"
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'test_duration_s': test_duration,
                'stability_checks': len(stability_checks),
                'avg_health_score': avg_health if stability_checks else 0,
                'min_health_score': min_health if stability_checks else 0,
                'health_variance': health_variance if stability_checks else 0
            }
            
            self._record_test_result(test_name, TestCategory.STRESS, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.STRESS, TestStatus.FAILED, duration_ms, str(e))
    
    async def _test_resource_exhaustion(self) -> None:
        """æµ‹è¯•èµ„æºè€—å°½åœºæ™¯"""
        test_name = "èµ„æºè€—å°½åœºæ™¯æµ‹è¯•"
        start_time = time.perf_counter()
        
        try:
            # æµ‹è¯•ç¼“å­˜å®¹é‡é™åˆ¶
            cache = IntelligentCache(max_size=100)  # å°å®¹é‡ç¼“å­˜
            await cache.start()
            
            try:
                # å†™å…¥è¶…è¿‡å®¹é‡çš„æ•°æ®
                write_count = 200
                for i in range(write_count):
                    await cache.put(f"key_{i}", f"large_value_{i}" * 100)  # è¾ƒå¤§çš„å€¼
                
                # éªŒè¯ç¼“å­˜å¤§å°é™åˆ¶
                stats = cache.get_cache_stats()
                assert stats['current_size'] <= 100, f"ç¼“å­˜å¤§å°è¶…é™: {stats['current_size']}"
                assert stats['evictions'] > 0, "æœªå‘ç”Ÿç¼“å­˜æ¸…ç†"
                
                # æµ‹è¯•ç¼“å­˜åœ¨èµ„æºå‹åŠ›ä¸‹çš„æ€§èƒ½
                hit_count = 0
                test_reads = 50
                
                for i in range(test_reads):
                    value = cache.get(f"key_{i + write_count - test_reads}")  # è¯»å–æœ€è¿‘çš„æ•°æ®
                    if value:
                        hit_count += 1
                
                hit_rate = hit_count / test_reads
                assert hit_rate > 0.8, f"èµ„æºå‹åŠ›ä¸‹ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {hit_rate:.1%}"
                
            finally:
                await cache.stop()
            
            duration_ms = (time.perf_counter() - start_time) * 1000
            details = {
                'cache_max_size': 100,
                'data_written': write_count,
                'evictions': stats.get('evictions', 0),
                'final_cache_size': stats.get('current_size', 0),
                'hit_rate_under_pressure': hit_rate
            }
            
            self._record_test_result(test_name, TestCategory.STRESS, TestStatus.PASSED, duration_ms, details=details)
            
        except Exception as e:
            duration_ms = (time.perf_counter() - start_time) * 1000
            self._record_test_result(test_name, TestCategory.STRESS, TestStatus.FAILED, duration_ms, str(e))
    
    def _record_test_result(self, test_name: str, category: TestCategory, status: TestStatus, 
                          duration_ms: float, error_message: str = "", details: Dict[str, Any] = None) -> None:
        """è®°å½•æµ‹è¯•ç»“æœ"""
        result = TestResult(
            test_name=test_name,
            category=category,
            status=status,
            duration_ms=duration_ms,
            error_message=error_message,
            details=details or {}
        )
        
        self.test_results.append(result)
        
        # æ›´æ–°ç»Ÿè®¡
        self.test_stats['total_tests'] += 1
        if status == TestStatus.PASSED:
            self.test_stats['passed_tests'] += 1
        elif status == TestStatus.FAILED:
            self.test_stats['failed_tests'] += 1
        elif status == TestStatus.SKIPPED:
            self.test_stats['skipped_tests'] += 1
        
        # è®°å½•æ—¥å¿—
        status_emoji = {
            TestStatus.PASSED: "âœ…",
            TestStatus.FAILED: "âŒ", 
            TestStatus.SKIPPED: "â­ï¸"
        }
        
        emoji = status_emoji.get(status, "â“")
        logger.info(f"{emoji} {test_name} ({category.name}): {status.name} ({duration_ms:.1f}ms)")
        
        if error_message:
            logger.error(f"   é”™è¯¯: {error_message}")
    
    def _generate_test_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        try:
            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            category_stats = {}
            for category in TestCategory:
                category_results = [r for r in self.test_results if r.category == category]
                category_stats[category.name] = {
                    'total': len(category_results),
                    'passed': len([r for r in category_results if r.status == TestStatus.PASSED]),
                    'failed': len([r for r in category_results if r.status == TestStatus.FAILED]),
                    'skipped': len([r for r in category_results if r.status == TestStatus.SKIPPED]),
                    'avg_duration_ms': sum(r.duration_ms for r in category_results) / len(category_results) if category_results else 0
                }
            
            # å¤±è´¥æµ‹è¯•è¯¦æƒ…
            failed_tests = [r for r in self.test_results if r.status == TestStatus.FAILED]
            
            # æ€§èƒ½ç»Ÿè®¡
            performance_tests = [r for r in self.test_results if r.category == TestCategory.PERFORMANCE]
            performance_summary = {}
            
            if performance_tests:
                performance_summary = {
                    'avg_duration_ms': sum(r.duration_ms for r in performance_tests) / len(performance_tests),
                    'max_duration_ms': max(r.duration_ms for r in performance_tests),
                    'min_duration_ms': min(r.duration_ms for r in performance_tests)
                }
            
            # è®¡ç®—æ€»ä½“æˆåŠŸç‡
            success_rate = self.test_stats['passed_tests'] / max(1, self.test_stats['total_tests'])
            
            return {
                'summary': {
                    'total_tests': self.test_stats['total_tests'],
                    'passed_tests': self.test_stats['passed_tests'],
                    'failed_tests': self.test_stats['failed_tests'],
                    'skipped_tests': self.test_stats['skipped_tests'],
                    'success_rate': success_rate,
                    'total_duration_ms': self.test_stats['total_duration_ms']
                },
                'category_breakdown': category_stats,
                'performance_summary': performance_summary,
                'failed_tests': [
                    {
                        'name': test.test_name,
                        'category': test.category.name,
                        'error': test.error_message,
                        'duration_ms': test.duration_ms
                    }
                    for test in failed_tests
                ],
                'detailed_results': [
                    {
                        'name': test.test_name,
                        'category': test.category.name,
                        'status': test.status.name,
                        'duration_ms': test.duration_ms,
                        'timestamp': test.timestamp,
                        'details': test.details
                    }
                    for test in self.test_results
                ],
                'test_environment': {
                    'components_tested': [
                        'enhanced_client', 'data_quality_engine', 'connection_monitor',
                        'performance_optimizer', 'fault_recovery_manager', 
                        'integration_manager', 'realtime_adapter', 'system_monitor'
                    ],
                    'test_symbols': self.test_config['test_symbols'],
                    'performance_threshold_ms': self.test_config['performance_threshold_ms'],
                    'quality_threshold': self.test_config['quality_threshold']
                }
            }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")
            return {'error': f'ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}'}


# ä¾¿æ·å‡½æ•°
def create_integration_test_suite() -> IntegrationTestSuite:
    """åˆ›å»ºé›†æˆæµ‹è¯•å¥—ä»¶"""
    return IntegrationTestSuite()


async def run_complete_integration_test():
    """è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•"""
    logger.info("ğŸš€ å¯åŠ¨TradingViewæ•°æ®æºæ¨¡å—å®Œæ•´é›†æˆæµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = create_integration_test_suite()
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        test_report = await test_suite.run_all_tests()
        
        # è¾“å‡ºæµ‹è¯•æŠ¥å‘Š
        print("\n" + "="*80)
        print("ğŸ“Š TradingViewæ•°æ®æºæ¨¡å—é›†æˆæµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        summary = test_report.get('summary', {})
        print(f"æµ‹è¯•æ€»æ•°: {summary.get('total_tests', 0)}")
        print(f"é€šè¿‡: {summary.get('passed_tests', 0)}")
        print(f"å¤±è´¥: {summary.get('failed_tests', 0)}")
        print(f"è·³è¿‡: {summary.get('skipped_tests', 0)}")
        print(f"æˆåŠŸç‡: {summary.get('success_rate', 0):.1%}")
        print(f"æ€»è€—æ—¶: {summary.get('total_duration_ms', 0):.1f}ms")
        
        # åˆ†ç±»ç»Ÿè®¡
        print("\nğŸ“‹ åˆ†ç±»ç»Ÿè®¡:")
        category_breakdown = test_report.get('category_breakdown', {})
        for category, stats in category_breakdown.items():
            print(f"  {category}: {stats['passed']}/{stats['total']} é€šè¿‡ "
                  f"(å¹³å‡è€—æ—¶: {stats['avg_duration_ms']:.1f}ms)")
        
        # å¤±è´¥æµ‹è¯•
        failed_tests = test_report.get('failed_tests', [])
        if failed_tests:
            print("\nâŒ å¤±è´¥æµ‹è¯•:")
            for test in failed_tests:
                print(f"  - {test['name']} ({test['category']}): {test['error']}")
        
        # æ€§èƒ½æ‘˜è¦
        performance_summary = test_report.get('performance_summary', {})
        if performance_summary:
            print(f"\nâš¡ æ€§èƒ½æ‘˜è¦:")
            print(f"  å¹³å‡è€—æ—¶: {performance_summary.get('avg_duration_ms', 0):.1f}ms")
            print(f"  æœ€å¤§è€—æ—¶: {performance_summary.get('max_duration_ms', 0):.1f}ms")
            print(f"  æœ€å°è€—æ—¶: {performance_summary.get('min_duration_ms', 0):.1f}ms")
        
        print("="*80)
        
        # åˆ¤æ–­æ•´ä½“æµ‹è¯•ç»“æœ
        if summary.get('success_rate', 0) >= 0.9:
            print("ğŸ‰ é›†æˆæµ‹è¯•æ•´ä½“é€šè¿‡ï¼TradingViewæ•°æ®æºæ¨¡å—å¢å¼ºåŠŸèƒ½è¿è¡Œè‰¯å¥½ã€‚")
            return True
        else:
            print("âš ï¸ é›†æˆæµ‹è¯•å‘ç°é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•å’Œä¼˜åŒ–ã€‚")
            return False
        
    except Exception as e:
        logger.error(f"é›†æˆæµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ é›†æˆæµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´é›†æˆæµ‹è¯•
    asyncio.run(run_complete_integration_test())